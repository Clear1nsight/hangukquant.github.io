{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"quantpylib","text":"DISCLAIMER  None of the information contained here or on hangukquant.substack.com or its affiliated platforms constitutes an offer (or solicitation of an offer) to buy or sell any currency, product or financial instrument, to make any investment, or to participate in any particular trading strategy, or a recommendation for any security or any third party. Trading involves real risks of loss and is solely your responsibility. Past performance is not indicative of future performance; material enclosed herein is for educational purposes only. There is absolutely no warranty or guarantee implied with this product. Use at your own risk. Trading is a risky operation.  COPYRIGHT  Sharing and distribution of any material taken herein is not allowed without express and written approval by HangukQuant, and is only intended for private usage. The code is meant for subscribers of hangukquant.substack.com and any member expressly allowed by HangukQuant.  <p>Welcome to the <code>quantpylib</code> repository! This repository is a Python package for quantitative trading and research, with in-house tools for powerful, fast, flexible and batteries-included quantitative backtesting, data retrieval and all things quant trading. The library is not specific to any strategy or trading instrument. Members are encouraged to participate in the contribution of the code.</p> <p>The code requires a 3.8+ version of Python to run.</p>"},{"location":"#table-of-contents","title":"Table of Contents","text":"<ol> <li>Installation</li> <li>User Documentation and Examples</li> <li>Running Tests</li> </ol>"},{"location":"#installation","title":"Installation","text":"<p>To install this library, users need to obtain access to the private Github repo by leaving your Github id on our post or directly requesting to be shortlisted (for unpaid readers) to HangukQuant by email (hangukquant@gmail.com).</p> <p>You can use <code>quantpylib</code> in your local Python environment after cloning our repository and running  <pre><code>python3 -m pip install -e.\n</code></pre> in the working directory with the <code>setup.py</code> Python script.</p> <p>To run our example scripts, you may run  <pre><code>python3 -m pip install -r example_requirements.txt\n</code></pre></p>"},{"location":"#user-documentation-and-examples","title":"User Documentation and Examples","text":"<p>Please refer to our user documentation and examples here.</p>"},{"location":"#running-tests","title":"Running Tests","text":"<p>Our test suites can be run using the <code>pytest</code> framework. To run all tests, run  <pre><code>python3 -m pip install pytest\npython3 -m pytest quantpylib/tests \n</code></pre> For more verbose test information, run <pre><code>python3 -m pytest quantpylib/tests -vs \n</code></pre> You can choose specific modules or scripts to test by specifying the path to the test suite <pre><code>python3 -m pytest quantpylib/tests/simulator\npython3 -m pytest quantpylib/tests/simulator/test_operators.py\n</code></pre> Contributors who modify the codebase should run all tests and verify the tests pass before submitting a Pull Request.</p>"},{"location":"datapoller/base/","title":"quantpylib.datapoller.base","text":""},{"location":"datapoller/base/#quantpylib.datapoller.base.BasePoller","title":"<code>BasePoller</code>","text":"<p>A base class for creating pollers to interact with various data sources.</p> <p>Attributes:</p> Name Type Description <code>pollers</code> <code>dict</code> <p>A dictionary of pollers for different data sources.</p> <code>default_src</code> <code>str</code> <p>The default data source to be used.</p> <code>stream_buffer</code> <code>defaultdict</code> <p>A dictionary that stores deque instances for streaming data. Each call to <code>stream_market_data</code> from <code>BasePoller</code> instances will have the market-data streamed  and appended in ascending (old to new) order to the <code>stream_buffer</code>, with length specified by <code>buffer_len</code>.</p>"},{"location":"datapoller/base/#quantpylib.datapoller.base.BasePoller.__init__","title":"<code>__init__(pollers, buffer_len=1000000000, default_src='')</code>","text":"<p>Initialize the BasePoller with pollers, stream buffer length, and default data source.</p> <p>Parameters:</p> Name Type Description Default <code>pollers</code> <code>dict</code> <p>A dictionary of pollers for different data sources.</p> required <code>buffer_len</code> <code>int</code> <p>Maximum length of the streaming buffer.</p> <code>1000000000</code> <code>default_src</code> <code>str</code> <p>The default data source to be used.</p> <code>''</code>"},{"location":"datapoller/crypto/","title":"quantpylib.datapoller.crypto","text":""},{"location":"datapoller/crypto/#quantpylib.datapoller.crypto.Crypto","title":"<code>Crypto</code>","text":"<p>             Bases: <code>BasePoller</code></p>"},{"location":"datapoller/crypto/#quantpylib.datapoller.crypto.Crypto.close_market_data_stream","title":"<code>close_market_data_stream(ticker, **kwargs)</code>  <code>async</code>","text":"<p>Terminate streaming for market data of a specific cryptocurrency. @poller(tag=\"stream\")</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Cryptocurrency ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/crypto/#quantpylib.datapoller.crypto.Crypto.get_ticker_fundamentals","title":"<code>get_ticker_fundamentals(ticker, **kwargs)</code>","text":"<p>Retrieve fundamentals data for a specific cryptocurrency. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Cryptocurrency ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Fundamentals data for the specified cryptocurrency from the selected data source.</p>"},{"location":"datapoller/crypto/#quantpylib.datapoller.crypto.Crypto.get_ticker_metadata","title":"<code>get_ticker_metadata(ticker, **kwargs)</code>","text":"<p>Retrieve metadata for a specific cryptocurrency. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Cryptocurrency ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Metadata for the specified cryptocurrency from the selected data source.</p>"},{"location":"datapoller/crypto/#quantpylib.datapoller.crypto.Crypto.get_trade_bars","title":"<code>get_trade_bars(**kwargs)</code>","text":"<p>Retrieve OHLCV trade bar data for cryptocurrencies. @ts_poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Trade bar data for the specified cryptocurrency from the selected data source.</p>"},{"location":"datapoller/crypto/#quantpylib.datapoller.crypto.Crypto.stream_market_data","title":"<code>stream_market_data(ticker, **kwargs)</code>  <code>async</code>","text":"<p>Stream market data for a specific cryptocurrency. @poller(tag=\"stream\") The data being streamed can be accessed by the attribute <code>stream_buffer</code>,  and the specific ticker stream accessed: <code>poller.stream_buffer[ticker]</code>.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Cryptocurrency ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p>"},{"location":"datapoller/currencies/","title":"quantpylib.datapoller.currencies","text":""},{"location":"datapoller/currencies/#quantpylib.datapoller.currencies.Currencies","title":"<code>Currencies</code>","text":"<p>             Bases: <code>BasePoller</code></p>"},{"location":"datapoller/currencies/#quantpylib.datapoller.currencies.Currencies.close_market_data_stream","title":"<code>close_market_data_stream(ticker, **kwargs)</code>  <code>async</code>","text":"<p>Terminate streaming for market data of a specific currency. @poller(tag=\"stream\")</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Currency ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Termination status for the streaming market data of the specified currency from the selected data source.</p>"},{"location":"datapoller/currencies/#quantpylib.datapoller.currencies.Currencies.get_ticker_metadata","title":"<code>get_ticker_metadata(ticker, **kwargs)</code>","text":"<p>Retrieve metadata for a specific currency. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Currency ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Metadata for the specified currency from the selected data source.</p>"},{"location":"datapoller/currencies/#quantpylib.datapoller.currencies.Currencies.get_trade_bars","title":"<code>get_trade_bars(**kwargs)</code>","text":"<p>Retrieve OHLCV trade bar data for currencies. @ts_poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Trade bar data for the specified currency from the selected data source.</p>"},{"location":"datapoller/currencies/#quantpylib.datapoller.currencies.Currencies.stream_market_data","title":"<code>stream_market_data(ticker, **kwargs)</code>  <code>async</code>","text":"<p>Stream market data for a specific currency. @poller(tag=\"stream\")</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Currency ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>Streaming market data for the specified currency from the selected data source.</p>"},{"location":"datapoller/datapoller/","title":"quantpylib.datapoller","text":"<p><code>quantpylib.datapoller</code> is a quant module used for multi-asset, multi-source/vendor/exchange financial data retrieval. </p> <p>The datapollers are categorized into their data-classes, with current support for: </p> <pre><code>- crypto\n- currencies \n- equities\n- exchange\n- metadata\n</code></pre> <p>The datasources supported are:</p> <pre><code>- binance\n- eodhd\n- oanda\n- phemex\n- yfinance\n</code></pre> <p>In general, a trader may have requirements for different asset-class/categories of financial data, subscriptions to  multiple data sources, with each data source supporting a subset of the asset-class universe. Each data source  has its own endpoints, parameters, rate-restrictions and authentication flow - the datapoller abstracts these concerns  to provide a seamless interface for data retrieval while attempting to maximize throughput. </p> <p>Each datapoller is derived from the base <code>quantpylib.datapoller.base.BasePoller</code> class and implements a set of methods, and routs the requests to the specified data source and endpoints. The supported data sources are written as wrappers  on the <code>quantpylib.wrappers</code> module, and their supported endpoints share the same function name as in the datapollers.  The different datapollers are accessible via the master data polling class, given in <code>quantpylib.datapoller.master.Datapoller</code> object instance. For instance, if we would like to get trade bars using the <code>quantpylib.datapoller.currencies.Currencies.get_trade_bars</code>, we can do so by creating a <code>obj = DataPoller(...)</code> instance, and calling <code>obj.currencies.get_trade_bars(...,src=\"oanda\")</code>. The function call is only valid if it is supported by both the datapoller and the datasource, which we can check by their matching  function signatures. In general each datasource has its own parameters to the vendor-specific endpoint, as well as different specifications (such as start time of OHLCV historical request in YYYY-MM-DD vs unix-timestamp), so the library provides a unified standard that convert between these specifications. In additional, the datapoller take in flexible arguments  to support the different configurations for each external API - it would alot easier to understand through the given examples.</p> <p>Note that each of the datasource wrappers are also designed to be available for use as standalone Python-SDKs. Supported datapollers and datasources are added and updated frequently.</p> <p>To understand the valid function signatures of each datapoller, we need to understand the function\u2019s decorator-type,  which is indicated <code>@poller</code> or <code>@ts_poller</code> in the documentation, and is defined in <code>quantpylib.datapoller.utils</code> module for polling or time-series polling respectively.  The default arguments are supplied through these decorators, which also provide parameter-standardization and parameter-guessing  for vendor/source-unique specifications. Source-specific arguments are documented in its corresponding data-wrapper.</p> <p>We now walkthrough how to construct a valid datapolling request and construct valid parameters to our datapollers for the various datasources. Note that the various endpoints and their matching  function name-signatures can be easily looked up in the search-bar (top right): </p> <p>We need more data sources, more data pollers and more data endpoints to support. If there is a particular functionality  you would like documented or implemented, please feel free to reach out to me @ hangukquant@gmail.com or submit a Github issue. Cheers.</p>"},{"location":"datapoller/datapoller/#walkthrough","title":"Walkthrough","text":"<p>Supposed we are interested in getting some OHLC(V) data for equities. From our <code>quantpylib.wrappers</code> library, we see that the datasources supported with equities data is <code>eodhd</code> and <code>yfinance</code>. Suppose we have no API access to <code>eodhd</code>, so we will make a request through  the <code>yfinance</code> library. To see what endpoints are available  in the <code>equities</code> datapoller, we can just look at the documentation page - the sidebar has a summary, which we see has a <code>get_trade_bars</code> method. The arguments are not specified, but it is tagged <code>@ts_poller</code>, which means the arguments to supply are  given by decorators, documented here. The augmented arguments are <code>ticker</code>, <code>start</code>, <code>end</code>, <code>periods</code> <code>granularity</code>, <code>granularity_multiplier</code> and <code>src</code>. We shall provide <code>ticker</code>, <code>start</code>, <code>periods</code> and <code>src</code> to make our request, and let the rest settle to default arguments.</p> <p>We already have the keys in our <code>.env</code> file in the current working directory, and we will make the following imports <pre><code>import os \nfrom dotenv import load_dotenv\nload_dotenv()\nfrom datetime import datetime\nfrom quantpylib.datapoller.master import DataPoller\n\nkeys = {\n    \"yfinance\": True,\n    \"eodhd\": os.getenv(\"EOD_KEY\"),\n    \"binance\": True,\n    \"phemex\": True,\n    \"oanda\": (\"practice\",os.getenv(\"OANDA_ACC\"),os.getenv(\"OANDA_KEY\")),\n    \"coinbase\": False,\n}\n</code></pre> We just instantiate a master datapoller with our keys, access the equities <code>get_trade_bars</code> method and specify <code>src=\"yfinance\"</code>, like this: <pre><code>datapoller = DataPoller(config_keys=keys)\ndf = datapoller.equities.get_trade_bars(\n    ticker=\"AAPL\",\n    start=datetime(2000,1,1),\n    periods=365,\n    src=\"yfinance\"\n)\nprint(df)\n</code></pre> This gives us a year-worth of data for the year 2000~2001: <pre><code>                               open      high       low     close     volume\ndatetime                                                                    \n2000-01-03 00:00:00-05:00  0.792742  0.850379  0.768648  0.846127  535796800\n2000-01-04 00:00:00-05:00  0.818254  0.836206  0.764869  0.774790  512377600\n2000-01-05 00:00:00-05:00  0.784238  0.835733  0.778569  0.786128  778321600\n2000-01-06 00:00:00-05:00  0.802191  0.808805  0.718098  0.718098  767972800\n2000-01-07 00:00:00-05:00  0.729436  0.763452  0.721878  0.752113  460734400\n...                             ...       ...       ...       ...        ...\n2000-12-22 00:00:00-05:00  0.213539  0.226768  0.213539  0.226768  318052000\n2000-12-26 00:00:00-05:00  0.224878  0.226768  0.215429  0.222044  216815200\n2000-12-27 00:00:00-05:00  0.216846  0.223933  0.214484  0.223933  325466400\n2000-12-28 00:00:00-05:00  0.217319  0.225823  0.216374  0.223933  305177600\n2000-12-29 00:00:00-05:00  0.222044  0.226768  0.219209  0.224878  630336000\n</code></pre> Now if we were to specify <code>end=datetime(2000,1,1)</code> instead of <code>start=datetime(2000,1,1)</code>, then  we will have data from 1999~2000. Or we can just specify  the <code>start</code>,<code>end</code> directly, which means we can exclude the  <code>periods</code> parameter, like this: <pre><code>df = datapoller.equities.get_trade_bars(\n    ticker=\"AAPL\",\n    start=datetime(2000,1,1),\n    end=datetime(2020,1,1),\n    src=\"yfinance\"\n)\nprint(df)\n</code></pre> to get  <pre><code>                                open       high        low      close     volume\ndatetime                                                                        \n2000-01-03 00:00:00-05:00   0.792742   0.850379   0.768648   0.846127  535796800\n2000-01-04 00:00:00-05:00   0.818254   0.836206   0.764869   0.774790  512377600\n2000-01-05 00:00:00-05:00   0.784238   0.835734   0.778569   0.786128  778321600\n2000-01-06 00:00:00-05:00   0.802191   0.808805   0.718097   0.718097  767972800\n2000-01-07 00:00:00-05:00   0.729436   0.763452   0.721878   0.752113  460734400\n...                              ...        ...        ...        ...        ...\n2019-12-24 00:00:00-05:00  69.250147  69.298799  68.819601  69.147980   48478800\n2019-12-26 00:00:00-05:00  69.281768  70.536927  69.252580  70.519897   93121200\n2019-12-27 00:00:00-05:00  70.814237  71.507495  70.084495  70.493149  146266000\n2019-12-30 00:00:00-05:00  70.410455  71.196148  69.379088  70.911545  144114400\n2019-12-31 00:00:00-05:00  70.524783  71.436962  70.425051  71.429665  100805600\n</code></pre> Under the hood, we are mapping the parameters to  the <code>quantpylib.wrappers.yfinance.YFinance.get_trade_bars</code> method. You may use this as a standalone SDK, but the parameters are alot more rigid. With the master datapoller, we can provide any 2 of the 3 of <code>start</code>, <code>end</code>, and <code>periods</code>. But <code>yfinance</code> does not support too many endpoints, and is also  not stable, albeit free. Suppose we have an API key for  <code>eodhd</code>, we don't need to change much code: <pre><code>df = datapoller.equities.get_trade_bars(\n    ticker=\"AAPL\",\n    start=datetime(2000,1,1),\n    end=datetime(2020,1,1),\n    src=\"eodhd\"\n)\nprint(df)\n</code></pre> <pre><code>                open      high       low     close  adjusted_close     volume\ndatetime                                                                     \n2000-01-03  104.8768  112.5040  101.6848  111.9328          0.8461  535796800\n2000-01-04  108.2480  110.6224  101.1920  102.5024          0.7748  512377600\n2000-01-05  103.7456  110.5664  102.9952  104.0032          0.7862  778321600\n2000-01-06  106.1200  107.0048   94.9984   94.9984          0.7181  767972800\n2000-01-07   96.4992  101.0016   95.5024   99.5008          0.7521  460734400\n...              ...       ...       ...       ...             ...        ...\n2024-03-28  171.7500  172.2300  170.5100  171.4800        171.4800   65672700\n2024-04-01  171.1900  171.2500  169.4800  170.0300        170.0300   46240500\n2024-04-02  169.0800  169.3400  168.2300  168.8400        168.8400   49329500\n2024-04-03  168.7900  170.6800  168.5800  169.6500        169.6500   47602100\n2024-04-04  170.2900  171.9200  168.8200  168.8200        168.8200   53289969\n</code></pre> Actually we don't even need <code>src=\"eodhd\"</code>, the equities datapoller has that as its default, and the <code>@ts_poller</code> decorator is capable of guessing some parameters. This of course routs the request to <code>quantpylib.wrappers.eodhd.Eodhd.get_trade_bars</code>. Different from the <code>yfinance</code> wrapper's <code>get_trade_bars</code> endpoint, there is an additional parameter <code>exchange=\"US\"</code>, that is specific to the <code>eodhd</code> REST API. They have parameters to identify which asset with the same  ticker the client is referring to, but this nomenclature is unique to this particular vendor. This parameter is actually also  guessed by the <code>@ts_poller</code> decorator, but if we know precisely what we want, we should pass it in as arguments, as we may guess wrongly - here is an example of <code>AAPL</code> on the US and Mexican exchanges: <pre><code>df = datapoller.equities.get_trade_bars(\n    ticker=\"AAPL\",\n    start=datetime(2000,1,1),\n    end=datetime(2020,1,1),\n    src=\"eodhd\",\n    exchange=\"US\"\n)\nprint(df)\ndf = datapoller.equities.get_trade_bars(\n    ticker=\"AAPL\",\n    start=datetime(2000,1,1),\n    end=datetime(2020,1,1),\n    src=\"eodhd\",\n    exchange=\"MX\"\n)\nprint(df)\n</code></pre> giving <pre><code>                open      high       low     close  adjusted_close     volume\ndatetime                                                                     \n2000-01-03  104.8768  112.5040  101.6848  111.9328          0.8461  535796800\n2000-01-04  108.2480  110.6224  101.1920  102.5024          0.7748  512377600\n2000-01-05  103.7456  110.5664  102.9952  104.0032          0.7862  778321600\n2000-01-06  106.1200  107.0048   94.9984   94.9984          0.7181  767972800\n2000-01-07   96.4992  101.0016   95.5024   99.5008          0.7521  460734400\n...              ...       ...       ...       ...             ...        ...\n2024-03-28  171.7500  172.2300  170.5100  171.4800        171.4800   65672700\n2024-04-01  171.1900  171.2500  169.4800  170.0300        170.0300   46240500\n2024-04-02  169.0800  169.3400  168.2300  168.8400        168.8400   49329500\n2024-04-03  168.7900  170.6800  168.5800  169.6500        169.6500   47602100\n2024-04-04  170.2900  171.9200  168.8200  168.8200        168.8200   53289969\n\n[6102 rows x 6 columns]\n                 open       high        low      close  adjusted_close   volume\ndatetime                                                                       \n2004-12-20   704.4184   704.4184   694.5484   697.9980         11.0377   722401\n2004-12-21   702.4780   704.4996   702.4780   703.8080         11.1296  1804322\n2004-12-27   705.1688   705.1688   705.1688   705.1688         11.1511   140000\n2005-01-05   738.7380   738.7380   738.7380   738.7380         11.6819    14560\n2005-03-07   471.2496   471.2496   471.2496   471.2496         14.9041   266000\n...               ...        ...        ...        ...             ...      ...\n2024-03-27  2846.0000  2874.9900  2842.0000  2874.4299       2874.4299     1941\n2024-04-01  2873.0000  2873.0000  2819.3500  2827.2100       2827.2100    16860\n2024-04-02  2808.0000  2813.6900  2792.5000  2799.7800       2799.7800    23005\n2024-04-03  2798.0000  2829.9900  2798.0000  2810.0000       2810.0000     7258\n2024-04-04  2810.0000  2839.9900  2800.0000  2807.0300       2807.0300     3685\n</code></pre> The best is no-guessing, where you specify the source-specific parameters explicitly. For example, this would raise Exception: <pre><code>df = datapoller.equities.get_trade_bars(\n    ticker=\"BTC-USD\",\n    start=datetime(2000,1,1),\n    end=datetime(2020,1,1),\n    src=\"eodhd\"\n)\n</code></pre> but if you change the request using <code>crypto</code> poller <pre><code>df = datapoller.crypto.get_trade_bars(\n    ticker=\"BTC-USD\",\n    start=datetime(2000,1,1),\n    end=datetime(2020,1,1),\n    src=\"eodhd\"\n)\nprint(df)\n</code></pre> we get <pre><code>                    open          high           low         close  adjusted_close       volume\ndatetime                                                                                       \n2010-07-17      0.049510      0.049510      0.049510      0.049510        0.049510            0\n2010-07-18      0.049510      0.049510      0.049510      0.049510        0.049510            0\n2010-07-19      0.085840      0.085840      0.085840      0.085840        0.085840            0\n2010-07-20      0.080800      0.080800      0.080800      0.080800        0.080800            0\n2010-07-21      0.074740      0.074740      0.074740      0.074740        0.074740            0\n...                  ...           ...           ...           ...             ...          ...\n2024-03-31  69647.779030  71377.779498  69624.868677  71333.647926    71333.647926  20050941373\n2024-04-01  71333.484717  71342.091454  68110.696020  69702.146113    69702.146113  34873527352\n2024-04-02  69705.024322  69708.381258  64586.594304  65446.974233    65446.974233  50705240709\n2024-04-03  65446.671764  66914.322564  64559.899948  65980.808650    65980.808650  34488018367\n2024-04-04  65975.696667  69291.254806  65113.796534  68508.841844    68508.841844  34439527442\n</code></pre> The purpose of the <code>@ts_poller</code> adds a layer of complexity, but it's purpose is to both be extremely flexible in the arguments the methods takes in, to generalize to arbitrary data-sources, while still providing the simplest possible unified-interface at the user-level by routing to the correct wrapper's endpoint. In fact, if we knew how they were routed, some 'wrong' calls actually work: <pre><code>df = datapoller.equities.get_trade_bars(\n    ticker=\"BTC-USD\",\n    start=datetime(2000,1,1),\n    end=datetime(2020,1,1),\n    src=\"eodhd\",\n    exchange=\"CC\"\n)\n</code></pre> this works because even though we are using the <code>equities</code> datapoller, we specified the <code>CC</code> exchange which maps to the  crypto asset class in the <code>eodhd</code> vendor. Of course, we do not  recommend such workarounds. Note that additional arguments to otherwise valid requests are simply ignored - this request is valid: <pre><code>df = datapoller.crypto.get_trade_bars(\n    ticker=\"BTC-USD\",\n    start=datetime(2000,1,1),\n    end=datetime(2020,1,1),\n    src=\"eodhd\",\n    gibberish=\"gibberish\"\n)\n</code></pre> Let's make a request to a <code>@poller</code> method, such as  the <code>quantpylib.datapoller.equities.get_ticker_fundamentals</code>. The <code>@poller</code> only asks for the <code>src</code> parameter,  while <code>get_ticker_fundamentals</code> asks for a <code>ticker</code> parameter, so we can do <pre><code>df=datapoller.equities.get_ticker_fundamentals(ticker=\"AAPL\",src=\"eodhd\")\n</code></pre> that routs to the <code>eodhd</code> wrapper. Everything else is the same.</p>"},{"location":"datapoller/datapoller/#safe-throttling","title":"Safe-Throttling","text":"<p>As far as possible, when the specified endpoint specifies rate-limits, rapid submission of requests are sent-through  to the data-vendor as quickly as possible, while respecting the rate-limits. This is done by using our custom semaphore-like logic, defined in the <code>quantpylib.throttler.rate_semaphore</code>. This is specific to each data-vendor, and each instance of the wrapper around  our data-source has its own resource-pool. This design is to maximise throughput of user-requests, and is supported in both asynchronous and synchronous methods. All requests submitted to a specific datasource with  throttle-support will be paced, with support for multi-threading or coroutines. For instance, suppose we do <pre><code>import threading\nimport requests\ntry:\n    def raw():\n        response=requests.get(f\"https://eodhd.com/api/fundamentals/AAPL.US?api_token={os.getenv('EOD_KEY')}&amp;fmt=json\")\n        if response.status_code == 429: raise Exception(\"TooManyTooFast\")\n        else: print(response.status_code)\n    req=lambda:datapoller.equities.get_ticker_fundamentals(ticker=\"AAPL\")\n    threads=[threading.Thread(target=raw,args=()) for i in range(500)]\n    # req=lambda:datapoller.equities.get_ticker_fundamentals(ticker=\"AAPL\")\n    # threads=[threading.Thread(target=req,args=()) for i in range(500)]\n    for thread in threads: thread.start()\n    for thread in threads: thread.join()\nexcept Exception as err:\n    print(err)\n</code></pre> The raw, multi-threaded request will eventually get rejected by the server with a <code>429 TooManyRequests</code> code, while if we try: <pre><code># req=lambda:datapoller.equities.get_ticker_fundamentals(ticker=\"AAPL\")\n# threads=[threading.Thread(target=raw,args=()) for i in range(500)]\nreq=lambda:datapoller.equities.get_ticker_fundamentals(ticker=\"AAPL\")\nthreads=[threading.Thread(target=req,args=()) for i in range(500)]\n</code></pre> the application will gracefully pace the execution of multiple threads and  not crash.</p>"},{"location":"datapoller/datapoller/#examples","title":"Examples","text":"<p>A number of examples are given. This would be the setup: <pre><code>import os \nimport asyncio\nfrom dotenv import load_dotenv\nload_dotenv()\nfrom datetime import datetime\nfrom quantpylib.datapoller.master import DataPoller\n\nkeys = {\n    \"yfinance\": True,\n    \"eodhd\": os.getenv(\"EOD_KEY\"),\n    \"binance\": True,\n    \"phemex\": True,\n    \"oanda\": (\"practice\",os.getenv(\"OANDA_ACC\"),os.getenv(\"OANDA_KEY\")),\n    \"coinbase\": False,\n}\n\ndatapoller = DataPoller(config_keys=keys)\n\nasync def main():\n    pass #code here\n\nif __name__ == \"__main__\":\n    asyncio.run(main())\n</code></pre></p>"},{"location":"datapoller/datapoller/#get-ohlcv","title":"Get OHLCV","text":"<p>Let's get OHLCV for crypto, currencies and equities. We get <code>AAPL</code>, <code>EUR_USD</code>, <code>BTCUSDT</code> OHLCV data from  the <code>equities</code>, <code>currencies</code> and <code>crypto</code> datapoller  using source <code>eodhd</code>, <code>oanda</code> and <code>binance</code> respectively.</p> <p><pre><code>start,end=datetime(2020,1,1),datetime.now()\ndf1=datapoller.equities.get_trade_bars(ticker=\"AAPL\",start=start,end=end,granularity=\"d\",src=\"eodhd\")\ndf2=datapoller.currencies.get_trade_bars(ticker=\"EUR_USD\",start=start,end=end,granularity=\"d\",src=\"oanda\")\ndf3=datapoller.crypto.get_trade_bars(ticker=\"BTCUSDT\",start=start,end=end,granularity=\"d\",src=\"binance\")\nprint(df1,df2,df3)\n</code></pre> We can go for other data-granularities: <pre><code>df=datapoller.currencies.get_trade_bars(ticker=\"EUR_USD\",granularity=\"h\",granularity_multiplier=4,start=start,end=end,src=\"oanda\")\nprint(df)\n</code></pre> and we get 4-hour candles: <pre><code>                              open     high      low    close  volume\ndatetime                                                             \n2020-01-01 22:00:00+00:00  1.12124  1.12246  1.12124  1.12209     673\n2020-01-02 02:00:00+00:00  1.12206  1.12247  1.12010  1.12044     700\n2020-01-02 06:00:00+00:00  1.12044  1.12140  1.12013  1.12032    2392\n2020-01-02 10:00:00+00:00  1.12034  1.12039  1.11830  1.11966    2610\n2020-01-02 14:00:00+00:00  1.11962  1.12030  1.11636  1.11700    4887\n...                            ...      ...      ...      ...     ...\n2024-04-04 17:00:00+00:00  1.08587  1.08620  1.08319  1.08374   13217\n2024-04-04 21:00:00+00:00  1.08401  1.08441  1.08350  1.08416    9891\n2024-04-05 01:00:00+00:00  1.08416  1.08431  1.08234  1.08264    7608\n2024-04-05 05:00:00+00:00  1.08263  1.08464  1.08226  1.08376    9345\n2024-04-05 09:00:00+00:00  1.08374  `1.08422  1.08350  1.08393    1436\n</code></pre> The datapoller routs to the <code>oanda</code> wrapper, and because Oanda places a limit of candles per request, given your polling-period and granularity desired, there may be multiple requests to  the Oanda REST API server to stitch together the non-overlapping periods. This is the advantage of our <code>datapoller</code> and <code>wrapper</code> interface - the user does not have to concern themselves with the source-specific limitations.</p>"},{"location":"datapoller/datapoller/#get-tick-historical","title":"Get Tick Historical","text":"<p>Some endpoints support historical data. <code>eodhd</code> has support for  tick data on the US-listed common-stocks. <pre><code>ticks=datapoller.equities.get_trade_ticks(ticker=\"META\",start=datetime(2023,4,3,0,0,0), end=datetime(2023,4,3,12,0,0))\nprint(ticks)\n</code></pre> We get: <pre><code>     ex mkt   price      seq  shares    sl sub_mkt             ts\n0     Q   K  211.00    77001       5  @ TI          1680508800013\n1     Q   K  211.42    77002       1  @ TI          1680508800013\n2     Q   K  210.99    77124      10  @ TI          1680508800017\n3     Q   K  211.42    77125       7  @ TI          1680508800017\n4     Q   K  211.42    77127      30  @ TI          1680508800017\n...  ..  ..     ...      ...     ...   ...     ...            ...\n2071  Q   Q  210.00  3635409      59  @FTI          1680523180411\n2072  Q   Q  210.00  3635410      41  @FTI          1680523180411\n2073  Q   K  210.00  3636017     800  @FT           1680523181713\n2074  Q   Q  210.00  3636650      20  @FTI          1680523184200\n2075  Q   K  210.00  3637810      27  @FTI          1680523185877\n\n[2076 rows x 8 columns]\n</code></pre></p>"},{"location":"datapoller/datapoller/#get-fundamentals","title":"Get Fundamentals","text":"<p>Some assets and datasources support fundamental data. We could  get fundamental data for Goldman Sachs and Ethereum like this: <pre><code>f1=datapoller.equities.get_ticker_fundamentals(ticker=\"GS\",src=\"eodhd\")\nf2=datapoller.crypto.get_ticker_fundamentals(ticker=\"ETH-USD\",src=\"eodhd\")\n</code></pre></p>"},{"location":"datapoller/datapoller/#get-exchange-universe","title":"Get Exchange Universe","text":"<p>We might also be interested in getting the listed set of tickers for  a data vendor or exchange. In the case of <code>eodhd</code>, a data vendor,  they support multiple exchanges. We can type in the search-bar (top right)  for the endpoint <code>get_tickers_in_exchange</code>, and we see <code>binance</code>, <code>eodhd</code> and <code>oanda</code> support this endpoint through the <code>exchange</code> datapoller. We can see that the <code>eodhd</code> endpoint takes in an <code>exchange</code> parameter, so we can ask for their US-listed stocks as follows: <pre><code>tickers = datapoller.exchange.get_tickers_in_exchange(exchange=\"US\",src=\"eodhd\")\n</code></pre> On the other hand Binance is already an exchange, so looking at their endpoint, we see that no additional argument is required, so we can do the route by (same for <code>oanda</code>)  <pre><code>tickers = datapoller.exchange.get_tickers_in_exchange(src=\"binance\")\ntickers = datapoller.exchange.get_tickers_in_exchange(src=\"oanda\")\n</code></pre> Note that the return type from these endpoints are mostly not-standardized, and no have fixed schema, except for the <code>get_trade_bars</code> and common methods. This is a point for improvement that we are hoping contributors can come in, as we need the manpower!</p>"},{"location":"datapoller/datapoller/#streaming-data","title":"Streaming Data","text":"<p>We are capable of streaming market data in an extremely simple interface. This is interfaced by an asynchronous method in the datapoller in question, and all streamed data is stored in the objects' <code>stream_buffer</code> attribute, which is a <code>collections.defaultdict</code> object with <code>deque</code> as the buffer for each streamed datapoint.</p> <p>We can see that both <code>eodhd</code> and <code>currencies</code> support it, so we can make request: <pre><code>await datapoller.currencies.stream_market_data(ticker=\"EURUSD\",src=\"eodhd\")\nwhile True:\n    print(datapoller.currencies.stream_buffer[\"EURUSD\"])\n    await asyncio.sleep(3)\n</code></pre> and we can print the instance of the <code>stream_buffer</code> anytime we want, which maintains the current stream state. The length of <code>stream_buffer</code> is controlled by the object instantiation for any datapoller instance, see <code>quantpylib.datapoller.base.BasePoller</code>. The first two iterations give: <pre><code>deque([], maxlen=1000000000)\ndeque([{'s': 'EURUSD', 'a': 1.0835, 'b': 1.0834, 'dc': '-0.0379', 'dd': '-0.0004', 'ppms': False, 't': 1712331637066}, {'s': 'EURUSD', 'a': 1.0835, 'b': 1.0834, 'dc': '-0.0378', 'dd': '-0.0004', 'ppms': False, 't': 1712331637140}, {'s': 'EURUSD', 'a': 1.0835, 'b': 1.0834, 'dc': '-0.0377', 'dd': '-0.0004', 'ppms': False, 't': 1712331637278}, \n    {'s': 'EURUSD', 'a': 1.0835, 'b': 1.0834, 'dc': '-0.0393', 'dd': '-0.0004', 'ppms': False, 't': 1712331637844}, {'s': 'EURUSD', 'a': 1.0835, 'b': 1.0834, 'dc': '-0.0383', 'dd': '-0.0004', 'ppms': False, 't': 1712331637948}, {'s': 'EURUSD', 'a': 1.0835, 'b': 1.0834, 'dc': '-0.0374', 'dd': '-0.0004', 'ppms': False, 't': 1712331638154}, \n    {'s': 'EURUSD', 'a': 1.0836, 'b': 1.0835, 'dc': '-0.0306', 'dd': '-0.0003', 'ppms': False, 't': 1712331638426}, {'s': 'EURUSD', 'a': 1.0835, 'b': 1.0835, 'dc': '-0.028', 'dd': '-0.0003', 'ppms': False, 't': 1712331638445}, {'s': 'EURUSD', 'a': 1.0835, 'b': 1.0835, 'dc': '-0.028', 'dd': '-0.0003', 'ppms': False, 't': 1712331638725}, {'s': 'EURUSD', 'a': 1.0835, 'b': 1.0835, 'dc': '-0.032', 'dd': '-0.0003', 'ppms': False, 't': 1712331638748}, {'s': 'EURUSD', 'a': 1.0835, 'b': 1.0835, 'dc': '-0.0283', 'dd': '-0.0003', 'ppms': False, 't': 1712331639048}], maxlen=1000000000)\n</code></pre> It gets too large afterwards to display here, but we will see that each iteration contains more data. Of course, you can stream the same assets from different data sources, different assets from the same data source, and so on...all of these are valid: <pre><code>await datapoller.currencies.stream_market_data(ticker=\"EURUSD\",src=\"eodhd\")\nawait datapoller.currencies.stream_market_data(ticker=\"EUR_USD\",src=\"oanda\")\nawait datapoller.equities.stream_market_data(ticker=\"AAPL\",src=\"eodhd\")\nawait datapoller.crypto.stream_market_data(ticker=\"BTC-USD\",src=\"eodhd\")\nwhile True:\n    print(datapoller.currencies.stream_buffer[\"EURUSD\"])\n    print(datapoller.currencies.stream_buffer[\"EUR_USD\"])\n    print(datapoller.equities.stream_buffer[\"AAPL\"])\n    print(datapoller.crypto.stream_buffer[\"BTC-USD\"])\n    await asyncio.sleep(3)\n</code></pre> Once we are done, we can close all of the streams. Note that the <code>await</code> lines above are executed one-after-another, to call concurrently, we can use <code>gather</code>, which we demonstrate in using for closing the streams: <pre><code>await asyncio.gather(\n    *[\n        datapoller.currencies.close_market_data_stream(ticker=\"EURUSD\",src=\"eodhd\"),\n        datapoller.currencies.close_market_data_stream(ticker=\"EUR_USD\",src=\"oanda\"),\n        datapoller.equities.close_market_data_stream(ticker=\"AAPL\",src=\"eodhd\"),\n        datapoller.crypto.close_market_data_stream(ticker=\"BTC-USD\",src=\"eodhd\")\n    ]\n)\n</code></pre></p>"},{"location":"datapoller/datapoller/#queries","title":"Queries","text":"<p>Some data vendors provide a functionality to input some string or alternatively formatted specification into their search engine. This is provided in the <code>quantpylib.datapoller.metadata.query_engine</code> method: <pre><code>query = datapoller.metadata.query_engine(query=\"AAPL\")\nprint(query)\n</code></pre> gives us <pre><code>      Code Exchange                                               Name          Type  ... Currency          ISIN previousClose  previousCloseDate\n0     AAPL       US                                          Apple Inc  Common Stock  ...      USD  US0378331005      168.8200         2024-04-04\n1     AAPL       BA                                      Apple Inc DRC  Common Stock  ...      ARS  US0378331005     8925.5000         2024-04-04\n2     AAPL       MX                                          Apple Inc  Common Stock  ...      MXN  US0378331005     2807.0300         2024-04-04\n3     AAPL      NEO                                      Apple Inc CDR  Common Stock  ...      CAD  CA03785Y1007       25.0400         2024-04-04\n4     AAPL       SN                                          Apple Inc  Common Stock  ...      USD  US0378331005      170.5200         2024-04-04\n5   AAPL34       SA                                          Apple Inc  Common Stock  ...      BRL  BRAAPLBDR004       42.8200         2024-04-04\n6     AAPU       US  Direxion Shares ETF Trust - Direxion Daily AAP...           ETF  ...      USD  US25461A8743       21.9100         2024-04-04\n7     AAPD       US  Direxion Shares ETF Trust - Direxion Daily AAP...           ETF  ...      USD  US25461A3041       23.0400         2024-04-04\n8     APLY       US           YieldMax AAPL Option Income Strategy ETF           ETF  ...      USD  US88634T8577       16.5600         2024-04-04\n9     3SAP       PA                                   Granite -3x AAPL           ETF  ...      EUR  XS2193970030       26.9500         2024-04-04\n10    APLY      NEO              APPLE (AAPL) Yield Shares Purpose ETF           ETF  ...      CAD          None       22.7000         2024-04-04\n11    3LAP       PA                                   Granite +3x AAPL           ETF  ...      EUR  XS2193969883       18.4260         2024-04-04\n12    SALE      LSE  Leverage Shares 3x Short Apple (AAPL) ETP Secu...           ETF  ...      EUR  XS2472334742        2.9949         2024-04-04\n13    3SAA    XETRA               Leverage Shares -3x Short Apple AAPL           ETF  ...      EUR  XS2472334742        2.9892         2024-04-04\n14    AAPY       US       Kurv Yield Premium Strategy Apple (AAPL) ETF           ETF  ...      USD          None       23.3839         2024-04-04\n</code></pre></p>"},{"location":"datapoller/equities/","title":"quantpylib.datapoller.equities","text":""},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities","title":"<code>Equities</code>","text":"<p>             Bases: <code>BasePoller</code></p>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.close_market_data_stream","title":"<code>close_market_data_stream(ticker, **kwargs)</code>  <code>async</code>","text":"<p>Terminate stream for ticker data. @poller(tag=\"stream\")</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_dividends","title":"<code>get_ticker_dividends(ticker, **kwargs)</code>","text":"<p>Retrieve ticker dividends. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_earnings_history","title":"<code>get_ticker_earnings_history(ticker, **kwargs)</code>","text":"<p>Retrieve ticker earnings history. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_earnings_trend","title":"<code>get_ticker_earnings_trend(ticker, **kwargs)</code>","text":"<p>Retrieve ticker earnings trend. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_financials","title":"<code>get_ticker_financials(ticker, **kwargs)</code>","text":"<p>Retrieve ticker financials. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_fundamentals","title":"<code>get_ticker_fundamentals(ticker, **kwargs)</code>","text":"<p>Retrieve ticker fundamentals. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_historical_mcap","title":"<code>get_ticker_historical_mcap(ticker, **kwargs)</code>","text":"<p>Retrieve ticker historical market cap. @ts_poller(assert_span=False, automap_span=False)</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_insider_txn","title":"<code>get_ticker_insider_txn(ticker, **kwargs)</code>","text":"<p>Retrieve ticker insider transactions. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_metadata","title":"<code>get_ticker_metadata(ticker, **kwargs)</code>","text":"<p>Retrieve ticker metadata. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_shares_stats","title":"<code>get_ticker_shares_stats(ticker, **kwargs)</code>","text":"<p>Retrieve ticker shares statistics. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_splits","title":"<code>get_ticker_splits(ticker, **kwargs)</code>","text":"<p>Retrieve ticker splits. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_ticker_stat_snapshot","title":"<code>get_ticker_stat_snapshot(ticker, **kwargs)</code>","text":"<p>Retrieve ticker statistical snapshot. @poller</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_trade_bars","title":"<code>get_trade_bars(**kwargs)</code>","text":"<p>Retrieve OHLC(V) trade bars data. @ts_poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.get_trade_ticks","title":"<code>get_trade_ticks(start, end, **kwargs)</code>","text":"<p>Retrieve ticker ticks data. @ts_poller(automap_span=False)</p> <p>Parameters:</p> Name Type Description Default <code>start</code> <code>datetime</code> <p>Start datetime.</p> required <code>end</code> <code>datetime</code> <p>End datetime.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/equities/#quantpylib.datapoller.equities.Equities.stream_market_data","title":"<code>stream_market_data(ticker, **kwargs)</code>  <code>async</code>","text":"<p>Stream ticker data. @poller(tag=\"stream\")</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol.</p> required <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code>"},{"location":"datapoller/exchange/","title":"quantpylib.datapoller.exchange","text":""},{"location":"datapoller/exchange/#quantpylib.datapoller.exchange.Exchange","title":"<code>Exchange</code>","text":"<p>             Bases: <code>BasePoller</code></p> <p>A class for interacting with exchange-related data sources.</p>"},{"location":"datapoller/exchange/#quantpylib.datapoller.exchange.Exchange.check_exchange_open","title":"<code>check_exchange_open(**kwargs)</code>","text":"<p>Check if the exchange is open for trading. @poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The exchange trading status from the selected data source.</p>"},{"location":"datapoller/exchange/#quantpylib.datapoller.exchange.Exchange.get_delisted_tickers_in_exchange","title":"<code>get_delisted_tickers_in_exchange(**kwargs)</code>","text":"<p>Retrieve the collection of delisted tickers in a specific exchange. @poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The collection of delisted tickers in the specified exchange from the selected data source.</p>"},{"location":"datapoller/exchange/#quantpylib.datapoller.exchange.Exchange.get_exchange_holidays","title":"<code>get_exchange_holidays(**kwargs)</code>","text":"<p>Retrieve the exchange holidays for a specific exchange. @poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The exchange holidays for the specified exchange from the selected data source.</p>"},{"location":"datapoller/exchange/#quantpylib.datapoller.exchange.Exchange.get_exchange_hours","title":"<code>get_exchange_hours(**kwargs)</code>","text":"<p>Retrieve the trading hours for a specific exchange. @poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The trading hours for the specified exchange from the selected data source.</p>"},{"location":"datapoller/exchange/#quantpylib.datapoller.exchange.Exchange.get_exchange_server_timestamp","title":"<code>get_exchange_server_timestamp(**kwargs)</code>","text":"<p>Retrieve the server timestamp for a specific exchange. @poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The server timestamp for the specified exchange from the selected data source.</p>"},{"location":"datapoller/exchange/#quantpylib.datapoller.exchange.Exchange.get_exchange_tz","title":"<code>get_exchange_tz(**kwargs)</code>","text":"<p>Retrieve the time zone for a specific exchange. @poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The time zone for the specified exchange from the selected data source.</p>"},{"location":"datapoller/exchange/#quantpylib.datapoller.exchange.Exchange.get_supported_exchanges","title":"<code>get_supported_exchanges(**kwargs)</code>","text":"<p>Retrieve the collection of supported exchanges. @poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The collection of supported exchanges from the selected data source.</p>"},{"location":"datapoller/exchange/#quantpylib.datapoller.exchange.Exchange.get_tickers_in_exchange","title":"<code>get_tickers_in_exchange(**kwargs)</code>","text":"<p>Retrieve the collection of tickers in a specific exchange. @poller</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <p>Data-source specific keyword arguments for endpoint specification.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The collection of tickers in the specified exchange from the selected data source.</p>"},{"location":"datapoller/master/","title":"quantpylib.datapoller.master","text":""},{"location":"datapoller/master/#quantpylib.datapoller.master.DataPoller","title":"<code>DataPoller</code>","text":""},{"location":"datapoller/master/#quantpylib.datapoller.master.DataPoller.__init__","title":"<code>__init__(config_keys={'yfinance': True, 'eodhd': os.getenv('EOD_KEY'), 'binance': True, 'phemex': True, 'oanda': ('practice', os.getenv('OANDA_ACC'), os.getenv('OANDA_KEY')), 'coinbase': False})</code>","text":"<p>Initialize the DataPoller class with the provided configuration keys. The configuration keys can be passed as string format to the appropriate key-value pair, but you should not hardcode it in production environments. You can create a <code>.env</code>file and place your keys there, or set it as environment variables. If you do not have the API keys, you can set the <code>value=False</code>, and this datasource will not  be available for data retrieval. All the datapollers are available through this master poller,  by accessing the attribute values <code>datapoller.equities</code>, <code>datapoller.crypto</code> and so on.</p> <p>Parameters:</p> Name Type Description Default <code>config_keys</code> <code>dict</code> <p>A dictionary containing configuration keys for different data sources.  The default configuration includes parameters for yfinance, eodhd, binance, phemex, and oanda.</p> <code>{'yfinance': True, 'eodhd': getenv('EOD_KEY'), 'binance': True, 'phemex': True, 'oanda': ('practice', getenv('OANDA_ACC'), getenv('OANDA_KEY')), 'coinbase': False}</code> <p>Attributes:</p> Name Type Description <code>equities</code> <code>Equities</code> <p>An instance of Equities that uses the specified data pollers and defaults to 'eodhd' as the source.</p> <code>metadata</code> <code>Metadata</code> <p>An instance of Metadata that uses the specified data pollers and defaults to 'eodhd' as the source.</p> <code>crypto</code> <code>Crypto</code> <p>An instance of Crypto that uses the specified data pollers and defaults to 'binance' as the source.</p> <code>currencies</code> <code>Currencies</code> <p>An instance of Currencies that uses the specified data pollers and defaults to 'eodhd' as the source.</p> <code>exchange</code> <code>Exchange</code> <p>An instance of Exchange that uses the specified data pollers and defaults to 'eodhd' as the source.</p>"},{"location":"datapoller/metadata/","title":"quantpylib.datapoller.metadata","text":""},{"location":"datapoller/metadata/#quantpylib.datapoller.metadata.Metadata","title":"<code>Metadata</code>","text":"<p>             Bases: <code>BasePoller</code></p>"},{"location":"datapoller/metadata/#quantpylib.datapoller.metadata.Metadata.query_engine","title":"<code>query_engine(query, **kwargs)</code>","text":"<p>Execute a query using a specific data poller.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The query to be executed.</p> required <code>**kwargs</code> <p>Additional keyword arguments for executing the query.</p> <code>{}</code> <p>Returns:</p> Type Description <p>The result of the query execution using the specified data poller.</p>"},{"location":"datapoller/utils/","title":"quantpylib.datapoller.utils","text":""},{"location":"datapoller/utils/#quantpylib.datapoller.utils.poller","title":"<code>poller(_func=None, *, tag=None)</code>","text":"<p>Decorator for instance level methods of <code>quantpylib.datapoller.base.BasePoller</code> objects.  Let the object be given the variable name <code>poller_obj</code>, then decorated instance level methods  have augmented default arguments <code>**kwargs</code> with following key-pairs:</p> <p>Specs:</p> <pre><code>src (string): Data source we want to poll for. Defaults to `poller_obj.default_src`.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>_func</code> <code>function</code> <p>The function to be decorated. Defaults to None.</p> <code>None</code> <code>tag</code> <code>str</code> <p>A tag to identify the poller. Defaults to None.</p> <code>None</code> <p>Returns:</p> Type Description <p>The decorated instance level method.</p>"},{"location":"datapoller/utils/#quantpylib.datapoller.utils.ts_poller","title":"<code>ts_poller(_func=None, *, tag=None, assert_span=True, automap_span=True)</code>","text":"<p>Decorator for instance level methods of <code>quantpylib.datapoller.base.BasePoller</code> objects.  Let the object be given the variable name <code>poller_obj</code>, then decorated instance level methods  have augmented default arguments <code>**kwargs</code> with following key-pairs:</p> <p>Specs:</p> <pre><code>ticker (str): The identifier for the time-series of interest. Defaults to None.\nstart (datetime.datetime): The start time of the time-series being polled. Defaults to None.\nend (datetime.datetime): The end time of the time-series being polled. Defaults to None.\nperiods (int): Number of periods of granularity_multiplier * granularity of time-series being polled. Defaults to None. \ngranularity (str): Granularity of data being polled. Valid values are ['s','m','h','d','w','M','y']. Defaults to 'd'.\ngranularity_multiplier (int): Multiplier for the granularity. For instance, 4 for multiplier and 'h' for granularity implies '4h' candles/periods. Defaults to 1.\nsrc (string): Data source we want to poll for. Defaults to `poller_obj.default_src`.\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>_func</code> <code>function</code> <p>The function to be decorated. Defaults to None.</p> <code>None</code> <code>tag</code> <code>str</code> <p>A tag to identify the poller. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>method</code> <p>The decorated instance level method.</p> <p>Parameters:</p> Name Type Description Default <code>_func</code> <code>function</code> <p>The function to be decorated. Defaults to None.</p> <code>None</code> <code>tag</code> <code>str</code> <p>A tag to identify the poller. Defaults to None.</p> <code>None</code> <code>assert_span</code> <code>bool</code> <p>Whether to assert the validity of time span arguments. If <code>True</code>, exactly two of <code>start</code>, <code>end</code>, and <code>periods</code> must be specified. Defaults to <code>True</code>.</p> <code>True</code> <code>automap_span</code> <code>bool</code> <p>Whether to automatically map (<code>start</code>,<code>end</code>,<code>periods</code>,<code>granularity</code>,<code>granularity_multiplier</code>) into time span arguments. Defaults to <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <p>The decorated instance level method.</p>"},{"location":"simulator/alpha/","title":"quantpylib.simulator.alpha","text":"<p><code>quantpylib.simulator.alpha</code> is our core backtesting module, and exposes multiple abstract  base classes that can be easily extended to implement your own custom trading strategies. <code>quantpylib.simulator.alpha.BaseAlpha</code> encodes the underlying backtest logic, and <code>quantpylib.simulator.alpha.Alpha</code> extends <code>BaseAlpha</code> and implements important features such that the user only has to write code for generating relative forecasts/signals. Position-sizing, risk-management, volatility targeting, PnL accounting and trade simulation is then handled by the backtest logic.</p> <p>In addition, we provide simple but powerful access to an assortment of performance metrics and hypothesis tests (monte carlo permutation tests) on any instance of the <code>BaseAlpha</code> object to test for strategy effectiveness.</p> <p>Users would likely only have to interact with the abstract <code>quantpylib.simulator.alpha.Alpha</code> class, and implement the<code>compute_forecasts</code> and <code>compute_signals</code> function in custom-classes that extend the <code>Alpha</code> class. Additionally, users may opt to use our automatic formulaic parser and use <code>quantpylib.simulator.gene.GeneticAlpha</code> that extends the <code>Alpha</code> class to opt for a no-code backtest by just encoding their trading strategy as a simple Python <code>str</code>, for which all the abstract functions would be automatically implemented.</p>  Using the quantpylib.simulator.gene.GeneticAlpha is the simplest and recommended way of using our BaseAlpha and Alpha classes, as no additional code needs to be written. If the primitives supported by our gene module is not sufficient to encode your trading strategy, then the Alpha class should be sufficient for most needs."},{"location":"simulator/alpha/#alpha","title":"Alpha","text":"<code>     __init__     </code> <p>Parameters:</p> Name Type Description Default <code>trade_range</code> <code>tuple</code> <p>Trading date range (start_date, end_date) of tz-aware datetime.datetime objects. Example would be <code>trade_range=(datetime(2000,1,1, tzinfo=pytz.utc),datetime.now(pytz.utc))</code></p> required <code>instruments</code> <code>list</code> <p>List of traded instruments.</p> <code>[]</code> <code>execrates</code> <code>ndarray</code> <p>Execution rates for each instrument. Default is None.</p> <code>None</code> <code>commrates</code> <code>ndarray</code> <p>Commission rates for each instrument. Default is None.</p> <code>None</code> <code>longswps</code> <code>ndarray</code> <p>Long swap rates for each instrument. Default is None.</p> <code>None</code> <code>shortswps</code> <code>ndarray</code> <p>Short swap rates for each instrument. Default is None.</p> <code>None</code> <code>dfs</code> <code>dict</code> <p>Dataframes used for computations. Default is an empty dictionary.</p> <code>{}</code> <code>positional_inertia</code> <code>float</code> <p>Parameter controlling position change inertia. Default is 0.</p> <code>0</code> <code>portfolio_vol</code> <code>float</code> <p>Target portfolio volatility. Default is 0.20, representing 20% annualized volatility.</p> <code>0.2</code> <code>currency_denomination</code> <code>str</code> <p>Currency denomination for the portfolio. Default is \"USD\".</p> <code>'USD'</code> Notes <p>execrates, commrates, longswps, shortswps are presented in decimals. <code>execrates = [0.001, 0.005, ...]</code> encodes that 0.1% of notional value transacted is deducted as execution costs. commrates specify commisions in the same  units (as percentage of notional value), as for overnight swap rates for both long and short positions.</p>  For the dfs dictionary passed into BaseAlpha objects, it should contain the DataFrames for all data required in the trading strategy. Minimally, dfs should contain key-value pair of (ticker:pd.DataFrame) with OHLCV data for PnL accounting. The pd.DataFrame objects provided should have timezone aware DatetimeIndex properties. For instance: <pre><code>{\n    'BRKB':\n                                open      high       low        close        adj_close volume\n    datetime\n    2000-01-03 00:00:00+00:00  1825.0000  1829.0000  1741.0000  1765.0000    35.3000   873500     \n    2000-01-04 00:00:00+00:00  1725.0000  1733.0000  1695.0000  1704.0000    34.0800  1380000     \n    2000-01-05 00:00:00+00:00  1707.0000  1773.0000  1695.0000  1732.0000    34.6400   997000     \n    2000-01-06 00:00:00+00:00  1745.0000  1804.0000  1727.0000  1804.0000    36.0800   917000     \n    2000-01-07 00:00:00+00:00  1830.0000  1848.0000  1805.0000  1820.0000    36.4000  1001500     \n    ...                              ...        ...        ...        ...        ...      ...     \n    2009-12-24 00:00:00+00:00  3281.9999  3295.9899  3274.9999  3286.9999    65.7400   607600     \n    2009-12-28 00:00:00+00:00  3279.9999  3289.9999  3274.9999  3285.3699    65.7074  1080250     \n    2009-12-29 00:00:00+00:00  3284.9999  3289.6899  3269.9999  3279.9999    65.6000  1105300     \n    2009-12-30 00:00:00+00:00  3282.9999  3289.6499  3279.9999  3289.6499    65.7930   560350     \n    2009-12-31 00:00:00+00:00  3289.9999  3300.9899  3279.9999  3285.9999    65.7200   972900 \n} \n</code></pre> <code>     compute_signals     </code> <code>async, abstract</code> <p>Abstract function that should be implemented in child-class extending the <code>Alpha</code> class. This is where users can manipulate the dataframes in <code>dfs</code> dict passed by accessing  <code>self.dfs</code> to compute useful metrics such as technical indicators.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>DatetimeIndex</code> <p>trade_range specified at daily granularity.</p> required <code>     compute_forecasts     </code> <code>abstract</code> <p>Abstract function that should be implemented in child-class extending the <code>Alpha</code> class. Computes relative forecasts for <code>self.instruments</code> on <code>date</code>.</p> <p>Parameters:</p> Name Type Description Default <code>portfolio_i</code> <p>Number of days passed between date and backtest start.</p> required <code>date</code> <code>datetime</code> <p>The date for which forecasts are to be computed.</p> required <code>eligibles_row</code> <code>ndarray</code> <p>An array mask of length <code>len(self.instruments)</code> that acts as a bit mask for eligible trading universe.</p> required <p>Returns:</p> Type Description <code>array</code> <p>An array representing the relative forecasts for each of instruments in <code>self.instruments</code> with length <code>len(self.instruments)</code>.</p> Note <p>It is not required for the forecasts to be indicative of the number of contracts the strategy should trade. The values in the returned array need only be indicative of the relative strength in the signal forecast. For instance, <code>[-1, 1, 1.5]</code> means we want to be as short the first instrument as we are long the second instrument, and we want to be longer by a factor of 1.5 in the third instrument as we are in the second instrument. Position sizing in the underlying contracts are dealt with automatically in the backtest engine using volatility  targeting at the instrument and strategy level. <code>np.nan</code>, <code>np.inf</code> values are treated as zero.</p> <code>     instantiate_eligibilities_and_strat_variables     </code> <p>This is where the child class can instantiate object attributes that can be used in the <code>compute_forecasts</code> function. Optional to implement. <code>eligiblesdf</code> is the default bit mask DataFrame encoding trading universe on  each date in <code>trade_range</code>, but it may be modified in an overriding method to use a different universe set throughout the backtest. </p> <p>Parameters:</p> Name Type Description Default <code>eligiblesdf</code> <code>DataFrame</code> <p>Bit mask DataFrame. Value of 1 means the instrument is eligible to be considered  for trading on given date, and value of 0 means not eligible. Computed based on the market data given in <code>self.dfs</code>.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>eligiblesdf is returned to the caller, and is used as the updated (if modified) bit-mask. If the function is not  implemented, the default <code>eligiblesdf</code> is used.</p> Note <p>This function is optional to implement. The default implemention is a one-liner returning <code>eligiblesdf</code>.</p> <p>The remaining functions are not abstract and no further implementation is required or warranted.</p> <code>     run_simulation     </code> <code>async</code> <p>Runs the entire backtest. Should only be called after concrete implementation of <code>compute_signals</code> and <code>compute_forecasts</code>.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <p>(boolean, optional) flag to print out backtest simulation information at runtime.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>a DataFrame containing backtest statistics. Contains information about contracts held throughtout the backtest, portfolio weights, portfolio leverage, nominal exposusure, execution costs, commissions, swaps, PnL, portfolio capital and so on.</p> <code>     get_performance_measures     </code> <p>Computes the performance metrics for the trading strategy.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing various performance metrics:</p> <ul> <li>\"cum_ret\": Cumulative returns over time.</li> <li>\"log_ret\": Logarithmic returns.</li> <li>\"max_dd\": Maximum drawdown.</li> <li>\"1y_roll_dd\": One-year rolling drawdown.</li> <li>\"1y_roll_max_dd\": One-year rolling maximum drawdown.</li> <li>\"sortino\": Sortino ratio.</li> <li>\"sharpe\": Sharpe ratio.</li> <li>\"mean_ret\": Mean return per annum.</li> <li>\"median_ret\": Median return per annum.</li> <li>\"stdev_ret\": Standard deviation of returns per annum.</li> <li>\"var_ret\": Variance of returns per annum.</li> <li>\"skew_ret\": Skewness of returns.</li> <li>\"kurt_exc\": Excess kurtosis of returns.</li> <li>\"cagr\": Compound annual growth rate.</li> <li>\"3y_roll_cagr\": Three-year rolling compound annual growth rate.</li> <li>\"3y_roll_calmar\": Three-year rolling Calmar ratio.</li> <li>\"omega(0)\": Omega ratio.</li> <li>\"ulcer\": Ulcer index.</li> <li>\"VaR95\": Value at Risk at 95% confidence level.</li> <li>\"cVaR95\": Conditional Value at Risk at 95% confidence level.</li> <li>\"gain_to_pain\": Gain-to-pain ratio.</li> <li>\"w_summary\": Summary statistics of weights.</li> <li>\"directionality\": Market long bias directionality.</li> <li>\"parity_distance\": Distance from a 1/n equal weight portfolio.</li> </ul> <code>     hypothesis_tests     </code> <code>async</code> <p>Conducts monte carlo permutation p-value hypothesis tests on the performance of the  trading strategy represented by the object instance.</p> <p>Parameters:</p> Name Type Description Default <code>num_decision_shuffles</code> <code>int</code> <p>Number of decision shuffles for monto carlo permutation tests. Default is 1000.</p> <code>1000</code> <code>num_data_shuffles</code> <code>int</code> <p>Number of data shuffles for permutation tests. Default is 10 (computationally expensive).</p> <code>10</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the results of hypothesis tests.</p> <ul> <li>'timer_p': p-value from asset-timing test that shuffles time-series asset returns.</li> <li>'picker_p': p-value from asset-picking shuffler test that shuffles cross-sectional asset returns.</li> <li>'trader_p1': p-value from decision-making test that shuffles both time-series and cross-sectional asset returns.</li> <li>'trader_p2': p-value from decision-making test that shuffles market data.</li> </ul>"},{"location":"simulator/gene/","title":"quantpylib.simulator.gene","text":"<p><code>quantpylib.simulator.gene</code> houses powerful features for numerical computations involving market  and non-market variables, including a no-code mathematical parser-evaluator that computes trading signals/indicators from formulaic, well-defined Python <code>str</code> objects. The parser-evaluator is exposed via the  <code>quantpylib.simulator.gene.Gene</code> class APIs, which internally uses a tree-data structure to encode trading formulas. The <code>quantpylib.simulator.gene.GeneticAlpha</code> class leverages this parser-evaluator, as well as the backtest engine provided by our <code>quantpylib.simulator.alpha.Alpha</code>  class to provide a no-code solution to backtesting trading strategies. The <code>GeneticAlpha</code> class  extends the <code>Alpha</code>   class to implement all the necessary methods for signal computation, forecast generation, position sizing, risk-management, volatility targeting and backtest logic. All the performance metrics and hypothesis testing suites made available to the <code>Alpha</code>  objects are naturally available to any <code>GeneticAlpha</code> instance via the same function signatures.</p>"},{"location":"simulator/gene/#geneticalpha","title":"GeneticAlpha","text":"<p>(Bases: <code>quantpylib.simulator.alpha.Alpha</code>  )</p> <p>Parameters:</p> Name Type Description Default <code>genome</code> <code>Gene or str</code> <p>Genome representation as <code>Gene</code> object or in mathematical string format.   </p> required <code>**kwargs</code> <p>Backtest parameters required to instantiate <code>quantpylib.simulator.alpha.Alpha</code> objects.</p> <code>{}</code> <p>Parameters in <code>**kwargs</code> are required and passed into <code>quantpylib.simulator.alpha.Alpha</code>  and are as follows: </p> <p>Parameters:</p> Name Type Description Default <code>trade_range</code> <code>tuple</code> <p>Trading date range (start_date, end_date) of tz-aware datetime.datetime objects. Example would be <code>trade_range=(datetime(2000,1,1, tzinfo=pytz.utc),datetime.now(pytz.utc))</code></p> required <code>instruments</code> <code>list</code> <p>List of traded instruments.</p> <code>[]</code> <code>execrates</code> <code>ndarray</code> <p>Execution rates for each instrument. Default is None.</p> <code>None</code> <code>commrates</code> <code>ndarray</code> <p>Commission rates for each instrument. Default is None.</p> <code>None</code> <code>longswps</code> <code>ndarray</code> <p>Long swap rates for each instrument. Default is None.</p> <code>None</code> <code>shortswps</code> <code>ndarray</code> <p>Short swap rates for each instrument. Default is None.</p> <code>None</code> <code>dfs</code> <code>dict</code> <p>Dataframes used for computations. Default is an empty dictionary.</p> <code>{}</code> <code>positional_inertia</code> <code>float</code> <p>Parameter controlling position change inertia. Default is 0.</p> <code>0</code> <code>portfolio_vol</code> <code>float</code> <p>Target portfolio volatility. Default is 0.20, representing 20% annualized volatility.</p> <code>0.2</code> <code>currency_denomination</code> <code>str</code> <p>Currency denomination for the portfolio. Default is \"USD\".</p> <code>'USD'</code> Notes <p>execrates, commrates, longswps, shortswps are presented in decimals. <code>execrates = [0.001, 0.005, ...]</code> encodes that 0.1% of notional value transacted is deducted as execution costs. commrates specify commisions in the same  units (as percentage of notional value), as for overnight swap rates for both long and short positions.</p> <code>     run_simulation     </code> <code>async</code> <p>Runs the entire backtest. </p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <p>(boolean, optional) flag to print out backtest simulation information at runtime.</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>a DataFrame containing backtest statistics. Contains information about contracts held throughtout the backtest, portfolio weights, portfolio leverage, nominal exposusure, execution costs, commissions, swaps, PnL, portfolio capital and so on.</p> <code>     get_performance_measures     </code> <p>Computes the performance metrics for the trading strategy.</p> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing various performance metrics:</p> <ul> <li>\"cum_ret\": Cumulative returns over time.</li> <li>\"log_ret\": Logarithmic returns.</li> <li>\"max_dd\": Maximum drawdown.</li> <li>\"1y_roll_dd\": One-year rolling drawdown.</li> <li>\"1y_roll_max_dd\": One-year rolling maximum drawdown.</li> <li>\"sortino\": Sortino ratio.</li> <li>\"sharpe\": Sharpe ratio.</li> <li>\"mean_ret\": Mean return per annum.</li> <li>\"median_ret\": Median return per annum.</li> <li>\"stdev_ret\": Standard deviation of returns per annum.</li> <li>\"var_ret\": Variance of returns per annum.</li> <li>\"skew_ret\": Skewness of returns.</li> <li>\"kurt_exc\": Excess kurtosis of returns.</li> <li>\"cagr\": Compound annual growth rate.</li> <li>\"3y_roll_cagr\": Three-year rolling compound annual growth rate.</li> <li>\"3y_roll_calmar\": Three-year rolling Calmar ratio.</li> <li>\"omega(0)\": Omega ratio.</li> <li>\"ulcer\": Ulcer index.</li> <li>\"VaR95\": Value at Risk at 95% confidence level.</li> <li>\"cVaR95\": Conditional Value at Risk at 95% confidence level.</li> <li>\"gain_to_pain\": Gain-to-pain ratio.</li> <li>\"w_summary\": Summary statistics of weights.</li> <li>\"directionality\": Market long bias directionality.</li> <li>\"parity_distance\": Distance from a 1/n equal weight portfolio.</li> </ul> <code>     hypothesis_tests     </code> <code>async</code> <p>Conducts monte carlo permutation p-value hypothesis tests on the performance of the  trading strategy represented by the object instance.</p> <p>Parameters:</p> Name Type Description Default <code>num_decision_shuffles</code> <code>int</code> <p>Number of decision shuffles for monto carlo permutation tests. Default is 1000.</p> <code>1000</code> <code>num_data_shuffles</code> <code>int</code> <p>Number of data shuffles for permutation tests. Default is 10 (computationally expensive).</p> <code>10</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing the results of hypothesis tests.</p> <ul> <li>'timer_p': p-value from asset-timing test that shuffles time-series asset returns.</li> <li>'picker_p': p-value from asset-picking shuffler test that shuffles cross-sectional asset returns.</li> <li>'trader_p1': p-value from decision-making test that shuffles both time-series and cross-sectional asset returns.</li> <li>'trader_p2': p-value from decision-making test that shuffles market data.</li> </ul>"},{"location":"simulator/gene/#gene","title":"<code>Gene</code>","text":"<p>Represents a formulaic alpha expression used to encode trading rules.</p> <p>This class internally represents a trading rule as a tree data structure, where each node can either be a terminal (leaf) node or a functional node. Terminal nodes represent data points or constants, while functional nodes represent operations on their child nodes.</p> <code>     str_to_gene     </code> <code>staticmethod</code> <p>Converts a string representation of a gene/formulaic alpha into a Gene object.</p> <p>Parameters:</p> Name Type Description Default <code>strgene</code> <code>str</code> <p>The string representation of the gene.</p> required <p>Returns:</p> Type Description <code>Gene</code> <p>A Gene object representing the gene.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If strgene representation is misspecified by syntax rules.</p> Note <p>This is the recommended and most intuitive way of creating a Gene object.</p> <code>     __init__     </code> <p>Initializes a Gene object.</p> <p>Parameters:</p> Name Type Description Default <code>prim</code> <code>str</code> <p>The primary function/terminal of the gene.</p> required <code>space</code> <code>str</code> <p>The space value associated with the gene, specifying      details of the primitive. For example, in the context of financial     trading, this could represent parameters such as window size or lookback     period of a rolling correlation function. Defaults to None.</p> <code>None</code> <code>is_terminal</code> <code>bool</code> <p>Indicates whether the gene is terminal node.</p> required <code>parent</code> <code>Gene</code> <p>The parent gene. Defaults to None.</p> <code>None</code> <code>children</code> <code>list</code> <p>The list of child genes. Defaults to an empty list.</p> <code>[]</code> <p>The list of <code>prim</code> primitives supported by our library, their behavior and their interpretations can be found here.</p> <code>     evaluate_node     </code> <p>Recursively evaluates a node in the formulaic alpha expression. When called on the root node in the  gene representation, this function evaluates the entire formulaic expression.</p> <p>Parameters:</p> Name Type Description Default <code>insts</code> <code>list</code> <p>The list of instrument names.</p> required <code>dfs</code> <code>dict</code> <p>A dictionary containing pricing/alternative data DataFrames for each instrument.</p> required <code>idx</code> <code>Index</code> <p>The index for alignment.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>The evaluated node with DataFrame.index=idx and DataFrame.columns=insts.</p>  dfs should contain DataFrames for all terminals required in the evaluation of the gene representation. For OHLCV terminals, dfs should contain key-value pair of (ticker:pd.DataFrame). pd.DataFrame objects provided should have timezone aware DatetimeIndex properties. For instance: <pre><code>{\n    'BRKB':\n                                open      high       low        close        adj_close volume\n    datetime\n    2000-01-03 00:00:00+00:00  1825.0000  1829.0000  1741.0000  1765.0000    35.3000   873500     \n    2000-01-04 00:00:00+00:00  1725.0000  1733.0000  1695.0000  1704.0000    34.0800  1380000     \n    2000-01-05 00:00:00+00:00  1707.0000  1773.0000  1695.0000  1732.0000    34.6400   997000     \n    2000-01-06 00:00:00+00:00  1745.0000  1804.0000  1727.0000  1804.0000    36.0800   917000     \n    2000-01-07 00:00:00+00:00  1830.0000  1848.0000  1805.0000  1820.0000    36.4000  1001500     \n    ...                              ...        ...        ...        ...        ...      ...     \n    2009-12-24 00:00:00+00:00  3281.9999  3295.9899  3274.9999  3286.9999    65.7400   607600     \n    2009-12-28 00:00:00+00:00  3279.9999  3289.9999  3274.9999  3285.3699    65.7074  1080250     \n    2009-12-29 00:00:00+00:00  3284.9999  3289.6899  3269.9999  3279.9999    65.6000  1105300     \n    2009-12-30 00:00:00+00:00  3282.9999  3289.6499  3279.9999  3289.6499    65.7930   560350     \n    2009-12-31 00:00:00+00:00  3289.9999  3300.9899  3279.9999  3285.9999    65.7200   972900 \n} \n</code></pre> For non-OHLCV terminals, dfs should be supplemented with key-value pair of (ticker_terminal:pd.Series). pd.Series objects provided should have timezone aware DatetimeIndex properties. <pre><code>{\n    'BRKB_earnings' : pd.Series(\n            index=[2000-01-03 00:00:00+00:00, ..., 2009-12-30 00:00:00+00:00],\n            data=[...]\n    ),\n    'BRKB_sentiment' : pd.Series(\n            index=[2010-01-03 00:00:00+00:00, ..., 2016-12-30 00:00:00+00:00],\n            data=[...]\n    )\n}\n</code></pre> <code>     make_dot     </code> <p>Generate a DOT language representation of the tree structure rooted at this node.</p> <p>Returns:</p> Type Description <code>str</code> <p>A string containing the DOT language representation of the tree.</p> Notes <p>This method uses pre-order traversal to generate the DOT representation of the tree rooted at the current node. Each node in the tree corresponds to a vertex in the DOT graph, and each edge represents the parent-child relationship between nodes.</p> <p>The generated DOT string can be rendered into a graphical visualization using graphviz or other tools that support the DOT language.</p> <code>     height     </code> <p>Return the maximium distance from current node to any leaf node that is a descendant.</p> <code>     depth     </code> <p>Return the distance from current node to the root node.</p> <code>     size     </code> <p>Return the number of nodes in the graphical respresentation of the formulaic alpha.</p> <code>     pre_ord_apply     </code> <p>Apply a function to each node in the tree using pre-order traversal.</p> <p>This method traverses the tree in a pre-order fashion, meaning it applies the function to the current node before recursively traversing its children. The function is applied to each node along with any additional keyword arguments provided.</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>callable</code> <p>A function to be applied to each node in the tree.</p> required <code>**kwargs</code> <p>Additional keyword arguments to be passed to the function.</p> <code>{}</code>"},{"location":"simulator/gene/#list-of-primitives","title":"List of Primitives","text":"<p>The Op value = <code>idx_op</code> can be taken to be default as <code>union_idx_op</code>, or when explicitly paired with the <code>un</code> Space value. It takes <code>intersect_idx_op</code> when paired with the <code>ix</code> Space value. Examples would be <code>plus(open,close)</code>, <code>plus_un(open,close)</code>, <code>plus_ix(open,close)</code>. The different operators and their behavior is documented here.</p> Primitive Space Op Terminal Args Meaning Example const int,float - Yes - represents a constant numerical value of x const_3.14 open - - Yes - open price open high - - Yes - high price high low - - Yes - low price low close - - Yes - close price close volume - - Yes - trade volume volume * - - Yes - custom variable * (e.g. epsEst, sentiment) abs - self_idx_op2 No 1 absolute value abs(minus(close,open)) neg - self_idx_op2 No 1 negation neg(minus(close,open)) log - self_idx_op2 No 1 natural logarithm (replacing inf with NaN) log(volume) sign - self_idx_op2 No 1 sign function sign(minus(close,open)) recpcal - self_idx_op2 No 1 reciprocal (replacing inf with NaN) recpcal(close) pow int self_idx_op2 No 1 power function (replacing inf with NaN) pow_2(close) csrank - all_idx_op No 1 cross-sectional rank (smallest=1, average draws) csrank(volume) cszscre - all_idx_op No 1 cross-sectional Z-score cszscre(volume) ls int,float / int,float all_idx_op No 1 -1 for values below 25 percentile and +1 for values above 75 percentile ls_25/75(volume) delta int self_idx_op No 1 time-series change in variable over time delta_1(close) delay int self_idx_op No 1 time-series delay by specified number of periods delay_1(close) sum int self_idx_op No 1 sum of time-series values sum_5(volume) prod int self_idx_op No 1 product of time-series values prod_5(volume) mean int self_idx_op No 1 mean of time-series values mean_5(volume) ewma int self_idx_op No 1 exponentially weighted moving average ewma_5(volume) median int self_idx_op No 1 median of time-series values median_5(volume) std int self_idx_op No 1 standard deviation of time-series values std_5(volume) var int self_idx_op No 1 variance of time-series values var_5(volume) skew int self_idx_op No 1 skewness of time-series values skew_5(volume) kurt int self_idx_op No 1 kurtosis of time-series values kurt_5(volume) tsrank int self_idx_op No 1 time-series rank tsrank_5(volume) tsmax int self_idx_op No 1 maximum value over time tsmax_5(volume) tsmin int self_idx_op No 1 minimum value over time tsmin_5(volume) tsargmax int self_idx_op No 1 index of maximum value over time tsargmax_5(volume) tsargmin int self_idx_op No 1 index of minimum value over time tsargmin_5(volume) tszscre int self_idx_op No 1 time-series Z-score tszscre_5(volume) max -,un,ix idx_op No &gt;=2 maximum over arguments max_ix(open,close,high) plus -,un,ix idx_op No &gt;=2 sum over arguments plus_un(open,close,high) minus -,un,ix idx_op No 2 subtraction minus(high,low) mult -,un,ix idx_op No 2 multiplication mult(open,close) div -,un,ix idx_op No 2 division div(open,close) and -,un,ix idx_op No 2 logical AND and(gt(high,low),lt(high,low)) or -,un,ix idx_op No 2 logical OR or(gt(high,low),lt(high,low)) eq -,un,ix idx_op No 2 logical EQUALS eq(gt(high,low),lt(high,low)) gt -,un,ix idx_op No 2 greater-than comparison gt(open,close) lt -,un,ix idx_op No 2 less-than comparison lt(open,close) ite -,un,ix idx_op No 3 if-then-else operation ite(or(gt(high,low),lt(high,low)),const_1,const_-1) cor int slow_idx_op No 2 rolling-correlation cor_12(volume,close) kentau int slow_idx_op No 2 rolling-Kendall's tau correlation kentau_12(volume,close) cov int slow_idx_op No 2 rolling-covariance cov_12(volume,close) grssret int - Pseudo 0 period gross returns grssret_12() logret int - Pseudo 0 period log returns logret_12() netret int - Pseudo 0 period net returns (gross returns - 1) netret_12() volatility int - Pseudo 0 volatility (standard deviation of log returns) volatility_12() rsi int - Pseudo 0 relative strength index indicator rsi_12() mvwap int - Pseudo 0 moving volume-weighted average price indicator mvwap_12() obv int - Pseudo 0 on-balance volume indicator obv_12() atr int - Pseudo 0 average true range indicator atr_12() tr - - Pseudo 0 true range indicator tr() adx int - Pseudo 0 average directional movement index adx_12() addv int - Pseudo 0 average daily dollar volume addv_12() mac int / int - No 1 moving average crossover indicator function for fast/slow mac_20/50(close)"},{"location":"simulator/operators/","title":"quantpylib.simulator.operators","text":"<p>The <code>quantpylib.simulator.operators</code> is a helper module consisting of operators that are used for data alignment in the evaluation of functions used by the <code>quantpylib.simulator.gene</code>'s Gene class. The semantics of the functions defined and how they operate on the arguments provided depend on the class of operators the primitive belongs. See the list of primitives here.</p> <p>For example, we may be interested in using as our trading signal the sum of <code>facebook_sentiment</code> and <code>twitter_sentiment</code>, where the former is sampled everyday  and latter is sampled only weekly. The formula <code>plus(facebook_sentiment,twitter_sentiment)</code> can have different interpretations depending on how we want to align data for which one or both of the arguments is <code>nan</code>.</p> <p> last-known basis: this phrase can be construed as forward filling DataFrames and applying the relevant operation.</p> <code>     all_idx_op(op, insts, al, win, *chress)     </code> <p>Apply a specified operation to each row of the provided DataFrame. Missing arguments applied on last-known basis.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>callable</code> <p>The operation to be applied to each row of the DataFrame. It must accept a pandas Series as input and return a pandas Series/numpy.ndarray of same length.</p> required <code>insts</code> <code>list of str</code> <p>List of instance names or identifiers. (Unused parameter, kept for function signature matching)</p> required <code>al</code> <code>DataFrame</code> <p>Alignment DataFrame. (Unused parameter, kept for function signature matching)</p> required <code>win</code> <code>int</code> <p>Window size for rolling operations. (Unused parameter, kept for function signature matching)</p> required <code>*chress</code> <code>DataFrame</code> <p>(one) DataFrame containing the time series data. The operation is applied to each row of this DataFrame.</p> <code>()</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the result of the operation applied to each row of the provided DataFrame.</p> <p>Examples: <pre><code>def test_all_idx_op(self):\n    data = {'inst1': [3,      5, 2,  np.nan, 8,   np.nan, np.nan, 10, np.nan, 7],\n            'inst2': [np.nan, 5, 12, 9,      15,  np.nan, 8,      13, 14,     11]\n            }\n    df = pd.DataFrame(data, index=pd.date_range(start='2022-01-01', periods=10, freq='D'))\n    result = all_idx_op(lambda x: scipy.stats.rankdata(x, method=\"average\", nan_policy=\"omit\"), [], None, None, df)\n    expected_data = {'inst1':[1.0,    1.5, 1.0, 1.0, 1.0, 1.0, 1.5, 1.0, 1.0, 1.0],\n                    'inst2': [np.nan, 1.5, 2.0, 2.0, 2.0, 2.0, 1.5, 2.0, 2.0, 2.0]}\n    expected_result = pd.DataFrame(expected_data, index=pd.date_range(start='2022-01-01', periods=10, freq='D'))\n\n    assert isinstance(result, pd.DataFrame)\n    assert result.index.equals(df.index)\n    assert result.columns.equals(df.columns)\n    pd.testing.assert_frame_equal(result, expected_result)\n</code></pre></p> <code>     intersect_idx_op(op, insts, al, win, *chress)     </code> <p>Perform a intersection operation on index labels and apply a given operation across multiple arrays or pandas DataFrames.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>callable</code> <p>The operation to be applied across arrays/DataFrames.</p> required <code>insts</code> <code>list</code> <p>List of instance names or identifiers.</p> required <code>aligner</code> <code>DataFrame</code> <p>A DataFrame with a pandas datetime index property to align the result DataFrame with.</p> required <code>win</code> <code>int</code> <p>Unused parameter to match the function signature of other operations.</p> required <code>*chress</code> <code>array - like or DataFrame</code> <p>Variable number of DataFrames containing time series data. Each DataFrame should have columns corresponding to the instance names provided in 'insts'.</p> <code>()</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the result of the operation applied to the input arrays/DataFrames.</p> <p>Examples: <pre><code>def test_intersect_idx_op(self):\n    data1 = {'inst1': [np.nan, 2.0,    3,      np.nan, 5], \n             'inst2': [6,      np.nan, 8,      9,      10]}\n\n    data2 = {'inst1': [1.0,    2,      np.nan, np.nan, 5], \n             'inst2': [11,     12,     13,     np.nan, 15]}\n    df1 = pd.DataFrame(data1, index=pd.date_range(start='2022-01-01', periods=5, freq='D'))\n    df2 = pd.DataFrame(data2, index=pd.date_range(start='2022-01-01', periods=5, freq='D'))\n    aligner = pd.DataFrame(index=pd.date_range(start='2022-01-01', periods=5, freq='D'))\n    result = intersect_idx_op(np.add, ['inst1', 'inst2'], aligner, -1, df1, df2)    \n    expected_data = {\n        'inst1': [np.nan, 4.0,    np.nan, np.nan, 10], \n        'inst2': [17.0,   np.nan, 21,     np.nan, 25]\n    }\n    expected_result = pd.DataFrame(\n        expected_data, index=pd.date_range(start='2022-01-01', periods=5,freq='D')\n    )\n\n    assert isinstance(result, pd.DataFrame)\n    assert result.index.equals(aligner.index)\n    assert result.columns.equals(expected_result.columns)\n    pd.testing.assert_frame_equal(result, expected_result)\n</code></pre></p> <code>     self_idx_op(op, insts, al, win, *chress)     </code> <p>Apply a specified operation to each instance in the provided time series data, using a rolling window. Missing arguments are ignored.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>callable</code> <p>The operation to be applied to each instance in the time series data.  It must accept a pandas Series as input and return a scalar value.</p> required <code>insts</code> <code>list of str</code> <p>List of instance names or identifiers.</p> required <code>aligner</code> <code>DataFrame</code> <p>A DataFrame with a pandas datetime index property to align the results.</p> required <code>win</code> <code>int</code> <p>Window size for the rolling computation.</p> required <code>*chress</code> <code>DataFrame</code> <p>(one) Dataframe containing the time series data. Each column corresponds to an instance provided in 'insts'.</p> <code>()</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the result of the operation applied to each instance, aligned with the provided aligner.</p> <p>Examples: <pre><code>def test_self_idx_op(self):\n    data = {'inst1': [1, 2,      3, np.nan, 5,  np.nan, np.nan, 8,  np.nan, 10],\n            'inst2': [6, np.nan, 8, 9,      10, np.nan, 12,     13, 14,     15]}\n    df = pd.DataFrame(data, index=pd.date_range(start='2022-01-01', periods=10, freq='D'))\n    aligner = pd.DataFrame(index=pd.date_range(start='2022-01-01', end='2022-01-10', freq='D'))\n    result = self_idx_op(np.mean, ['inst1', 'inst2'], aligner, 3, df)\n\n    expected_data = {\n        'inst1': [\n            np.nan, np.nan, 2.0,    np.nan,   3.333333, np.nan, np.nan,    5.333333,  np.nan, 7.666667\n        ],\n        'inst2': [\n            np.nan, np.nan, np.nan, 7.666667, 9.0,      np.nan, 10.333333, 11.666667, 13.0,   14.0\n        ]\n    }\n    expected_result = pd.DataFrame(expected_data, index=pd.date_range(start='2022-01-01', periods=10, freq='D'))\n\n    assert isinstance(result, pd.DataFrame)\n    assert result.index.equals(aligner.index)\n    assert result.columns.equals(expected_result.columns)\n    pd.testing.assert_frame_equal(result, expected_result)\n</code></pre></p> <code>     self_idx_op2(op, insts, al, win, *chress)     </code> <p>Apply a specified unary transformation to the provided time series data.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>callable</code> <p>The operation to be applied to the provided time series data. It must accept a pandas DataFrame as input and return a pandas DataFrame.</p> required <code>insts</code> <code>list of str</code> <p>List of instance names or identifiers. (Unused parameter, kept for function signature matching)</p> required <code>al</code> <code>DataFrame</code> <p>Alignment DataFrame. (Unused parameter, kept for function signature matching)</p> required <code>win</code> <code>int</code> <p>Window size for rolling operations. (Unused parameter, kept for function signature matching)</p> required <code>*chress</code> <code>DataFrame</code> <p>(one) DataFrame containing the time series data. The operation is applied to this DataFrame.</p> <code>()</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Result of applying the operation to the provided time series data. The output DataFrame will have the same index and columns as the input DataFrame.</p> <p>Examples: <pre><code>def test_self_idx_op2(self):\n    data = {'inst1': [1, 2,      3, np.nan, 5,  np.nan, np.nan, 8,  np.nan, 10],\n            'inst2': [6, np.nan, 8, 9,      10, np.nan, 12,     13, 14,     15]}\n    df = pd.DataFrame(data, index=pd.date_range(start='2022-01-01', periods=10, freq='D'))\n    result = self_idx_op2(lambda x: -1 * x, [], None, None, df)\n\n    expected_data = {'inst1':[-1, -2,     -3, np.nan, -5,  np.nan, np.nan, -8,  np.nan, -10],\n                    'inst2': [-6, np.nan, -8, -9,     -10, np.nan, -12,    -13, -14,    -15]\n                }\n    expected_result = pd.DataFrame(\n        expected_data, index=pd.date_range(start='2022-01-01', periods=10, freq='D')\n    )\n\n    assert isinstance(result, pd.DataFrame)\n    assert result.index.equals(df.index)\n    assert result.columns.equals(df.columns)\n    pd.testing.assert_frame_equal(result, expected_result)\n</code></pre></p> <code>     slow_idx_op(op, insts, al, win, *chress)     </code> <p>Apply a specified operation to aligned time series data, potentially handling unequal indices. The reference indices aligned to for each inst is the argument with the smallest number of data points. Missing arguments applied on last-known basis.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>callable</code> <p>The operation to be applied across time series data. It must accept numpy arrays as input.</p> required <code>insts</code> <code>list of str</code> <p>List of instance names or identifiers.</p> required <code>aligner</code> <code>DataFrame</code> <p>A DataFrame with a pandas datetime index property to determine the common index for alignment.</p> required <code>win</code> <code>int</code> <p>Window size for rolling computation. Used for operations that involve a rolling window, such as rolling correlation.</p> required <code>*chress</code> <code>DataFrame</code> <p>Variable number of DataFrames containing time series data. Each DataFrame should have columns corresponding to the instance names provided in 'insts'.</p> <code>()</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the result of the operation applied to the aligned time series data.</p> <p>Examples: <pre><code>def test_slow_idx_op(self):\n    data1 = {\n        'inst1': [np.nan, 2,      3,      np.nan, 5,  6,      np.nan, 8,  9,      10], #7 data points\n        'inst2': [6,      np.nan, 8,      9,      10, np.nan, 12,     13, np.nan, 15] #7 data points\n    }\n    data2 = {\n        'inst1': [1,      2,      np.nan, 4,      5,  6,      7,      8, 9,       10], #9 data points\n        'inst2': [11,     12,     13,     np.nan, 15, 16,     17,     18, np.nan, 20] #8 data points\n    }\n    df1 = pd.DataFrame(data1, index=pd.date_range(start='2022-01-01', periods=10, freq='D'))\n    df2 = pd.DataFrame(data2, index=pd.date_range(start='2022-01-01', periods=10, freq='D'))\n    aligner = pd.DataFrame(index=pd.date_range(start='2022-01-01', end='2022-01-10', freq='D'))\n    result = slow_idx_op(lambda a,b:np.add(a,b)[0], ['inst1', 'inst2'], aligner, 1, df1, df2)\n    expected_data = {\n        'inst1': [np.nan, 4.0,    5.0,  np.nan, 10.0, 12.0,   np.nan, 16.0, 18.0,   20.0], #min(7,9)=7, choose df1.inst1.index as reference\n        'inst2': [17.0,   np.nan, 21.0, 22.0,   25.0, np.nan, 29.0,   31.0, np.nan, 35.0] #min(7,8)=7, choose df1.inst2.index as reference\n    }\n    expected_result = pd.DataFrame(expected_data, index=pd.date_range(start='2022-01-01', periods=10, freq='D'))\n    assert isinstance(result, pd.DataFrame)\n    assert result.index.equals(aligner.index)\n    assert result.columns.equals(expected_result.columns)\n    pd.testing.assert_frame_equal(result, expected_result)\n</code></pre></p> <code>     union_idx_op(op, insts, al, win, *chress)     </code> <p>Perform a union operation on index labels and apply a given operation across multiple arrays or pandas DataFrames. Missing arguments applied on last-known basis.</p> <p>Parameters:</p> Name Type Description Default <code>op</code> <code>callable</code> <p>The operation to be applied across arrays/DataFrames.</p> required <code>insts</code> <code>list</code> <p>List of instance names or identifiers.</p> required <code>aligner</code> <code>DataFrame</code> <p>A DataFrame with a pandas datetime index property to align the result DataFrame with.</p> required <code>win</code> <code>int</code> <p>Unused parameter to match the function signature of other operations.</p> required <code>*chress</code> <code>array - like or DataFrame</code> <p>Variable number of DataFrames containing time series data. Each DataFrame should have columns corresponding to the instance names provided in 'insts'.</p> <code>()</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>A DataFrame containing the result of the operation applied to the input arrays/DataFrames.</p> <p>Examples: <pre><code>def test_union_idx_op(self):\n    data1 = {'inst1': [np.nan, 2.0,    3,      np.nan, 5], \n             'inst2': [6,      np.nan, 8,      9,      10]}\n    data2 = {'inst1': [1.0,    2,      np.nan, np.nan, 5], \n             'inst2': [11,     12,     13,     np.nan, 15]}\n    df1 = pd.DataFrame(data1, index=pd.date_range(start='2022-01-01', periods=5, freq='D'))\n    df2 = pd.DataFrame(data2, index=pd.date_range(start='2022-01-01', periods=5, freq='D'))\n    aligner = pd.DataFrame(index=pd.date_range(start='2022-01-01', periods=5, freq='D'))\n\n    result = union_idx_op(np.add, ['inst1', 'inst2'], aligner, -1, df1, df2)\n\n    expected_data = {\n        'inst1': [np.nan, 4.0, 5,  np.nan, 10], \n        'inst2': [17.0,   18,  21, 22,     25]\n    }\n    expected_result = pd.DataFrame(expected_data, index=pd.date_range(start='2022-01-01', periods=5, freq='D'))\n\n    assert isinstance(result, pd.DataFrame)\n    assert result.index.equals(aligner.index)\n    assert result.columns.equals(expected_result.columns)\n    pd.testing.assert_frame_equal(result, expected_result)\n</code></pre></p>"},{"location":"simulator/performance/","title":"quantpylib.simulator.performance","text":""},{"location":"simulator/performance/#quantpylib.simulator.performance.performance_measures","title":"<code>performance_measures(r, w, plot=False, path=FOLDER_STRUCTURE.images_dir)</code>","text":"<p>Calculate and visualize various performance measures of a trading strategy.</p> <p>Parameters:</p> Name Type Description Default <code>r</code> <code>Series</code> <p>Time series of returns.</p> required <code>w</code> <code>DataFrame</code> <p>DataFrame of weights corresponding to each asset over time, with same index as r.</p> required <code>plot</code> <code>bool</code> <p>Whether to generate and save plots. Defaults to True.</p> <code>False</code> <code>path</code> <code>str</code> <p>Path to save generated plots, if plot=True</p> <code>images_dir</code> <p>Returns:</p> Type Description <code>dict</code> <p>A dictionary containing various performance metrics:</p> <ul> <li>\"cum_ret\": Cumulative returns over time.</li> <li>\"log_ret\": Logarithmic returns.</li> <li>\"max_dd\": Maximum drawdown.</li> <li>\"1y_roll_dd\": One-year rolling drawdown.</li> <li>\"1y_roll_max_dd\": One-year rolling maximum drawdown.</li> <li>\"sortino\": Sortino ratio.</li> <li>\"sharpe\": Sharpe ratio.</li> <li>\"mean_ret\": Mean return per annum.</li> <li>\"median_ret\": Median return per annum.</li> <li>\"stdev_ret\": Standard deviation of returns per annum.</li> <li>\"var_ret\": Variance of returns per annum.</li> <li>\"skew_ret\": Skewness of returns.</li> <li>\"kurt_exc\": Excess kurtosis of returns.</li> <li>\"cagr\": Compound annual growth rate.</li> <li>\"3y_roll_cagr\": Three-year rolling compound annual growth rate.</li> <li>\"3y_roll_calmar\": Three-year rolling Calmar ratio.</li> <li>\"omega(0)\": Omega ratio.</li> <li>\"ulcer\": Ulcer index.</li> <li>\"VaR95\": Value at Risk at 95% confidence level.</li> <li>\"cVaR95\": Conditional Value at Risk at 95% confidence level.</li> <li>\"gain_to_pain\": Gain-to-pain ratio.</li> <li>\"w_summary\": Summary statistics of weights.</li> <li>\"directionality\": Market long bias directionality.</li> <li>\"parity_distance\": Distance from a 1/n equal weight portfolio.</li> </ul>"},{"location":"simulator/simulator/","title":"simulator","text":"<p>This page describes how you may use our <code>quantpylib.simulator</code> module and the functionalities exposed by our APIs. This module provides comprehensive backtesting functionality and statistical tools to analyse your own trading strategies. The core backtesting engine is made available via the <code>quantpylib.simulator.alpha</code> module's <code>Alpha</code> class, which leverages in-house statistical packages such as monte-carlo permutation hypothesis tests and performance metrics computation. This feature is further enhanced by our evaluator-parser in the <code>quantpylib.simulator.gene</code> module's <code>Gene</code> class, which is leveraged by the <code>GeneticAlpha</code> class to bring simple, efficient, accurate and no-code 'batteries-included' backtesting functionality.</p> <p>A high-level walkthrough of the individual quant packages are presented in this page. Comprehensive documentation may be found in the respective pages. To follow along, make sure you have installed the necessary dependencies. Code example scripts are also provided in the repo. Suppose we would like to test some trading strategy ideas, as well as run some tests and performance metrics on them. The trading strategies may be encoded via the succinct rules as follows: <pre><code>example1=\"ls_10/90(mult(div(minus(low,close),minus(high,low)),div(open,close)))\"\nexample2=\"ls_10/90(neg(mean_5(csrank(div(logret_5(),volatility_12())))))\" \nexample3=\"mac_50/100(close)\"\n</code></pre> <code>example1</code> tests for some intraday-effects, <code>example2</code> tests for mean-reversionary effects on risk-adjusted returns, and <code>example3</code> is a simple trend following strategy. The first two-examples are long-short market neutral strategies and third-example is a long-only strategy.</p>"},{"location":"simulator/simulator/#examples","title":"Examples","text":""},{"location":"simulator/simulator/#backtesting","title":"Backtesting","text":"<p>In this section we demonstrate how to run backtesting with <code>quantpylib.simulator.alpha</code>. We would need the following imports:</p> <p><pre><code>import pytz\nimport yfinance\nimport requests\nimport threading\nimport pandas as pd\nimport numpy as np\nfrom datetime import datetime\nfrom bs4 import BeautifulSoup\nimport matplotlib.pyplot as plt \n\nfrom quantpylib.simulator.alpha import Alpha\nfrom quantpylib.simulator.gene import GeneticAlpha\n</code></pre> First, determine the universe of instruments you would like to trade. Take for instance, the SP500 universe. We would poll this from wikipedia and take the first 100 tickers polled, and then get their  historical OHLCV data from <code>yfinance</code>. We would like to test for a period from 1 Jan 2000 to the current date.</p> <p>We write some code to poll data from the free open-source <code>yfinance</code> library:</p>  Code for Polling OHLCV Data  <pre><code>def get_sp500_tickers():\n    res = requests.get(\"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\")\n    soup = BeautifulSoup(res.content,'html')\n    table = soup.find_all('table')[0] \n    df = pd.read_html(str(table))\n    tickers = list(df[0].Symbol)\n    return tickers\n\ndef get_history(ticker,period_start,period_end,granularity=\"1d\",tries=0):\n    try:\n        df = yfinance.Ticker(ticker).history(\n            start=period_start,\n            end=period_end,\n            interval=granularity,\n            auto_adjust=True\n        ).reset_index()\n    except Exception as err:\n        if tries &lt; 5:\n            return get_history(ticker,period_start,period_end,granularity,tries+1)\n        return pd.DataFrame()\n\n    df = df.rename(columns={\n        \"Date\":\"datetime\",\n        \"Open\":\"open\",\n        \"High\":\"high\",\n        \"Low\":\"low\",\n        \"Close\":\"close\",\n        \"Volume\":\"volume\"\n    })\n    if df.empty:\n        return pd.DataFrame()\n    df.datetime = pd.DatetimeIndex(df.datetime.dt.date).tz_localize(pytz.utc)\n    df = df.drop(columns=[\"Dividends\", \"Stock Splits\"])\n    df = df.set_index(\"datetime\",drop=True)\n    return df\n\ndef get_histories(tickers, period_starts,period_ends, granularity=\"1d\"):\n    dfs = [None]*len(tickers)\n    def _helper(i):\n        print(tickers[i])\n        df = get_history(\n            tickers[i],\n            period_starts[i], \n            period_ends[i], \n            granularity=granularity\n        )\n        dfs[i] = df\n    threads = [threading.Thread(target=_helper,args=(i,)) for i in range(len(tickers))]\n    [thread.start() for thread in threads]\n    [thread.join() for thread in threads]\n    tickers = [tickers[i] for i in range(len(tickers)) if not dfs[i].empty]\n    dfs = [df for df in dfs if not df.empty]\n    return tickers, dfs\n\ndef get_ticker_dfs(start,end,tickers):\n    starts=[start]*len(tickers)\n    ends=[end]*len(tickers)\n    tickers,dfs = get_histories(tickers,starts,ends,granularity=\"1d\")\n    ticker_dfs = {ticker:df for ticker,df in zip(tickers,dfs)}    \n    return tickers, ticker_dfs \n</code></pre> <p>We now want to use our <code>quantpylib.simulator.alpha.Alpha</code> class engine to drive our backtest simulations. We would have to implement the abstract methods to test out our trading strategy. The abstract methods are  <code>compute_signals</code>, <code>compute_forecasts</code>. The documentation also suggests that we may optionally implement  <code>instantiate_eligibilities_and_strat_variables</code> to refine our trading universe. </p> <p>Let's create a class for that  <pre><code>class Example1(Alpha):\n    async def compute_signals(self,index=None):\n        pass\n\n    def instantiate_eligibilities_and_strat_variables(self, eligiblesdf):\n        pass\n\n    def compute_forecasts(self, portfolio_i, date, eligibles_row):\n        pass\n</code></pre></p> <p>Let us fill in the blanks to get a concrete implementation:</p> <pre><code>class Example1(Alpha):\n    async def compute_signals(self,index=None):\n        '''\n        ls_10/90(\n            mult(\n                div(\n                    minus(low,close),\n                    minus(high,low)\n                ),\n                div(open,close)\n            )\n        )\n        '''\n        alphas = []\n        for inst in self.instruments:\n            alpha = (self.dfs[inst].low - self.dfs[inst].close) \\\n                / (self.dfs[inst].high - self.dfs[inst].low ) \\\n                * (self.dfs[inst].open / self.dfs[inst].close)\n            alphas.append(alpha.replace([np.inf, -np.inf], np.nan))\n\n        alphadf = pd.concat(alphas, axis=1) #outer join, take the union of the different datetime indices\n        alphadf.columns = self.instruments\n        alphadf = pd.DataFrame(index=index).join(alphadf).fillna(method=\"ffill\")\n        is_short = lambda x: x &lt; np.nanpercentile(x,10)\n        is_long = lambda x: x &gt; np.nanpercentile(x,90)\n        self.alphadf = alphadf.apply(lambda row: (-1*(0+is_short(row)))+(0+is_long(row)),axis=1)\n\n    def instantiate_eligibilities_and_strat_variables(self, eligiblesdf):\n        eligblesdf = eligiblesdf &amp; (~pd.isna(self.alphadf))\n        return eligblesdf\n\n    def compute_forecasts(self, portfolio_i, date, eligibles_row):\n        forecast = self.alphadf.loc[date]\n        return forecast\n</code></pre> <p>We notice that the alpha forecast is an array of values consisting of elements of <code>[-1,0,1]</code>, representing short, neutral and long positions respectively. It should be noted that this alpha forecast is not restricted any set of discrete values, or magnitude - only the relative scale of the forecasts w.r.t other values in the array matter. Our <code>Alpha</code> backtesting engine automatically adjusts for the position sizing cross sectionally and across time through a combination of forecast size, instrument volatility and strategy volatility, using volatility targeting as risk control. The volatility targeted may be set by a (optional) parameter <code>portfolio_vol</code> to an instance of the <code>Alpha</code> class in the constructor. Now, we can call the <code>async</code> <code>run_simulation</code> method to get backtest results.</p> <p>The <code>Alpha</code> class takes in some parameters for our backtest strategy, including backtest date ranges, tickers and ticker data. Let's try to run our strategy now:</p> <p><pre><code>async def main():\n    example1=\"ls_10/90(mult(div(minus(low,close),minus(high,low)),div(open,close)))\" #https://hangukquant.substack.com/p/formulaic-alphas-7cd example1.pdf\n    example2=\"ls_10/90(neg(mean_5(csrank(div(logret_5(),volatility_12())))))\" #https://hangukquant.substack.com/p/formulaic-alphas-27b example2.pdf\n    example3=\"mac_50/100(close)\"\n\n    period_start = datetime(2000,1,1, tzinfo=pytz.utc)\n    period_end = datetime.now(pytz.utc)\n    tickers = get_sp500_tickers()[:100]\n    tickers, ticker_dfs = get_ticker_dfs(start=period_start,end=period_end,tickers=tickers)\n    configs={\n        \"instruments\":tickers,\n        \"dfs\":ticker_dfs,\n        \"trade_range\":(period_start,period_end),\n    }\n\n    alpha1 = Example1(**configs)\n    df1 = await alpha1.run_simulation()\n    print(df1)\n\nif __name__ == \"__main__\":\n    import asyncio\n    asyncio.run(main())    \n</code></pre> We obtain an output in our console a dataframe consisting of the details of our backtest simulations: <pre><code>terminal value 1237397.022956312\n                           MMM units  AOS units    ABT units  ADBE units  AES units  AFL units  A units  ...  exec_penalty  comm_penalty  swap_penalty  cost_penalty  nominal_ret  capital_ret       capital\n2000-01-01 00:00:00+00:00        0.0        0.0     0.000000    0.000000   0.000000   0.000000      0.0  ...           0.0           0.0           0.0           0.0     0.000000     0.000000  1.000000e+04\n2000-01-02 00:00:00+00:00        0.0        0.0     0.000000    0.000000   0.000000   0.000000      0.0  ...           0.0           0.0           0.0           0.0     0.000000     0.000000  1.000000e+04\n2000-01-03 00:00:00+00:00        0.0        0.0     0.000000    0.000000   0.000000   0.000000      0.0  ...           0.0           0.0           0.0           0.0     0.000000     0.000000  1.000000e+04\n2000-01-04 00:00:00+00:00        0.0        0.0     0.000000    0.000000   0.000000   0.000000      0.0  ...           0.0           0.0           0.0           0.0     0.000000     0.000000  1.000000e+04\n2000-01-05 00:00:00+00:00        0.0        0.0     0.000000    0.000000  -2.207572   8.323184      0.0  ...           0.0           0.0           0.0           0.0     0.000000     0.000000  1.000000e+04\n...                              ...        ...          ...         ...        ...        ...      ...  ...           ...           ...           ...           ...          ...          ...           ...\n2024-02-02 00:00:00+00:00        0.0        0.0  2491.717072 -296.303782   0.000000   0.000000      0.0  ...           0.0           0.0          -0.0           0.0     0.004586     0.005435  1.235953e+06\n2024-02-03 00:00:00+00:00        0.0        0.0  2540.356454 -302.087758   0.000000   0.000000      0.0  ...           0.0           0.0           0.0           0.0     0.000000     0.000000  1.235953e+06\n2024-02-04 00:00:00+00:00        0.0        0.0  2540.356454 -302.087758   0.000000   0.000000      0.0  ...           0.0           0.0           0.0           0.0     0.000000     0.000000  1.235953e+06\n2024-02-05 00:00:00+00:00        0.0        0.0     0.000000    0.000000   0.000000   0.000000      0.0  ...           0.0           0.0          -0.0           0.0     0.001004     0.001168  1.237397e+06\n2024-02-06 00:00:00+00:00        0.0        0.0     0.000000    0.000000   0.000000   0.000000      0.0  ...           0.0           0.0           0.0           0.0     0.000000     0.000000  1.237397e+06\n</code></pre> From this dataframe, we are able to see our pnl, individual positions held, portfolio allocation, notional exposure, leverage, trading costs (swap/execution/commissions if defined) and more.</p>"},{"location":"simulator/simulator/#no-code-backtesting","title":"No-Code Backtesting","text":"<p>Continuing with our code from the Backtesting section, although all we had to do was to implement a couple or so abstract methods for signal computation and forecasts depending our strategy/formula, we want to take an even more hands-off approach and skip implementing the signal logic all together. A no-code solution gives us a more robust approach, as we may make errors in the implementation of the signal compute. For instance, since the division operator involved in the formula for <code>Example1</code> may cause <code>ZeroDivisionError</code>, without the line <code>alphas.append(alpha.replace([np.inf, -np.inf], np.nan))</code>, we would be making logical errors.</p> <p>The functionality to parse mathematical/formulaic strings and evaluate them is implemented in our <code>quantpylib.simulator.gene.Gene</code> class and made accessible as an <code>Alpha</code> instance via the <code>quantpylib.simulator.gene.GeneticAlpha</code> module. The <code>GeneticAlpha</code> class inherits from the <code>Alpha</code> class like <code>Example1</code>, but instead of having to implement the three functions, all the computation is done via an automatic evaluator and the abstract methods are implemented internally.</p> <p>The <code>GeneticAlpha</code> takes a <code>str</code> or <code>Gene</code> object in addition to the parameters in the <code>Alpha</code> object. The formulaic representation, syntax and primitives supported by our <code>Gene</code> parser is given here.</p> <p>Continuing from the previous code, <pre><code>async def main():\n\n    '''\n    ...\n    '''\n\n    _alpha1 = GeneticAlpha(genome=example1,**configs)\n    _df1 = await _alpha1.run_simulation()\n    print(_df1)\n\n    alpha2 = GeneticAlpha(genome=example2,**configs)\n    alpha3 = GeneticAlpha(genome=example3,**configs, portfolio_vol=0.10)\n    df2 = await alpha2.run_simulation()\n    df3 = await alpha3.run_simulation()\n    print(df2)    \n    print(df3)\n</code></pre> All three examples are well defined and supported by our parser-evaluator, so we can get the backtest results without having to write logic code. We may plot their logarithmic wealth: <pre><code>    plt.plot(np.log(df1.capital),label=\"1\")\n    plt.plot(np.log(df2.capital),label=\"2\")\n    plt.plot(np.log(df3.capital),label=\"3\")\n    plt.legend()\n    plt.show()\n</code></pre> </p>"},{"location":"simulator/simulator/#performance-metrics-and-hypothesis-tests","title":"Performance Metrics and Hypothesis Tests","text":"<p>Our batteries-included feature gives us an access to powerful statistical tools to evaluate our trading strategy with a simple function call. This is supported by any <code>BaseAlpha</code> instance, which is indeed sufficed by both <code>Alpha</code> and <code>GeneticAlpha</code> instances.</p> <p><pre><code>async def main():\n\n    '''\n    ...\n    '''\n    print(alpha1.get_performance_measures())\n    print(await alpha1.hypothesis_tests())\n\n    print(_alpha1.get_performance_measures())\n    print(await _alpha1.hypothesis_tests())\n</code></pre> We get access to a wide array of performance measures, including sharpe ratio, sortino ratio, cagr, rolling-cagr, drawdown, VaR and more. The full list should be referenced here. We also get access to monte-carlo permutation hypothesis tests for asset picking, asset timing and overall decision making skills in the trading strategy.</p>"},{"location":"simulator/simulator/#simulatoralpha","title":"simulator.alpha","text":""},{"location":"simulator/simulator/#simulatorgene","title":"simulator.gene","text":""},{"location":"simulator/simulator/#simulatoroperators","title":"simulator.operators","text":""},{"location":"simulator/simulator/#simulatorperformance","title":"simulator.performance","text":""},{"location":"standards/standards/","title":"quantpylib.standards","text":""},{"location":"standards/standards/#quantpylib.standards.standards.Period","title":"<code>Period</code>","text":"<p>             Bases: <code>Enum</code></p> <p>Enumeration representing different time periods for supported data granularity.</p> <p>Attributes:</p> Name Type Description <code>SECOND</code> <p>Represents a second. Value <code>s</code>.</p> <code>MINUTE</code> <p>Represents a minute. Value <code>m</code>.</p> <code>HOURLY</code> <p>Represents an hour. Value <code>h</code>.</p> <code>DAILY</code> <p>Represents a day. Value <code>d</code>.</p> <code>WEEKLY</code> <p>Represents a week. Value <code>w</code>.</p> <code>MONTHLY</code> <p>Represents a month. Value <code>M</code>.</p> <code>YEARLY</code> <p>Represents a year. Value <code>y</code>.</p>"},{"location":"standards/standards/#quantpylib.standards.standards.get_span","title":"<code>get_span(granularity, granularity_multiplier, period_start=None, period_end=None, periods=None)</code>","text":"<p>Get the time span based on the specified granularity and parameters. granularity, granularity_multipler and periods determine the span duration, if provided.</p> <p>Parameters:</p> Name Type Description Default <code>granularity</code> <code>Period</code> <p>The granularity of time period.</p> required <code>granularity_multiplier</code> <code>int</code> <p>The multiplier for the granularity.</p> required <code>period_start</code> <code>datetime</code> <p>The start of the time period. Defaults to None.</p> <code>None</code> <code>period_end</code> <code>datetime</code> <p>The end of the time period. Defaults to None.</p> <code>None</code> <code>periods</code> <code>int</code> <p>The number of periods. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>tuple</code> <p>A tuple containing the (start,end) of timespan.</p> <p>Raises:</p> Type Description <code>InvalidPeriodConfig</code> <p>If the period configuration is invalid.</p> <code>AssertionError</code> <p>If the provided parameters are invalid.</p>"},{"location":"standards/standards/#quantpylib.standards.standards.map_granularity_to_relativedelta","title":"<code>map_granularity_to_relativedelta(granularity, periods)</code>","text":"<p>Map granularity and number of periods to <code>dateutil.relativedelta.relativedelta</code> object.</p> <p>Parameters:</p> Name Type Description Default <code>granularity</code> <code>Period</code> <p>The granularity of time period.</p> required <code>periods</code> <code>int</code> <p>The number of periods.</p> required <p>Returns:</p> Name Type Description <code>relativedelta</code> <p>Relative delta representing the time period.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the granularity is not a supported type.</p>"},{"location":"throttler/decorators/","title":"quantpylib.throttler.decorators","text":"<p>Examples for both decorator usage, and synchronous, asynchronous semaphores are given here.</p>"},{"location":"throttler/decorators/#quantpylib.throttler.decorators.aconsume_credits","title":"<code>aconsume_credits(_func=None, *, costs, refund_in, attrname='rate_semaphore', timeout=0, verbose=False)</code>","text":"<p>Decorator to wrap an asynchronous instance-level coroutine as an asynchronous transaction within a rate-limited semaphore. The return value is the return value of the decorated coroutine.</p> <p>Parameters:</p> Name Type Description Default <code>_func</code> <code>coroutine</code> <p>The asynchronous coroutine to be wrapped.</p> <code>None</code> <code>costs</code> <code>float</code> <p>The number of credits required for the transaction.</p> required <code>refund_in</code> <code>float</code> <p>The time in seconds after which the credits should be refunded.</p> required <code>attrname</code> <code>str</code> <p>The attribute name to access the AsyncRateSemaphore belonging to the object instance. Defaults to \"rate_semaphore\".</p> <code>'rate_semaphore'</code> <code>timeout</code> <code>float</code> <p>The maximum time in seconds to wait for the transaction to complete. Defaults to 0, which waits indefinitely.</p> <code>0</code> <code>verbose</code> <code>bool</code> <p>Whether to print verbose transaction information. Defaults to True.</p> <code>False</code> <p>Returns:</p> Type Description <code>any</code> <p>The return value of the decorated coroutine.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the instance does not have the specified attribute or if costs is less than 0.</p> <code>TimeoutError</code> <p>If wrapped transaction takes longer than the specified timeout.</p> Notes <p>For a timed-out transaction that does not get a chance to run due to it sitting  behind other transactions that are opportunistically processed,  a <code>RuntimeWarning: Enable tracemalloc to get the object allocation traceback</code>  may be seen together with the <code>asyncio.TimeoutError</code>. This is because the transaction  contains the coroutine, and the transact is wrapped in an asyncio <code>task</code>.  If it is unable to enter the semaphore by timeout,  the coroutine is never awaited and complains when garbage collected.  If the timeout occurs after the coroutine has acquired the semaphore,  this warning will not be seen but the <code>asyncio.TimeoutError</code> will still  be thrown.</p>"},{"location":"throttler/decorators/#quantpylib.throttler.decorators.consume_credits","title":"<code>consume_credits(_func=None, *, costs, refund_in, attrname='rate_semaphore', verbose=False)</code>","text":"<p>Decorator to wrap an synchronous instance-level method as an synchronous transaction within a rate-limited semaphore. The return value is the return value of the decorated method.</p> <p>Parameters:</p> Name Type Description Default <code>_func</code> <code>callable</code> <p>The method to be wrapped.</p> <code>None</code> <code>costs</code> <code>float</code> <p>The number of credits required for the transaction.</p> required <code>refund_in</code> <code>float</code> <p>The time in seconds after which the credits should be refunded.</p> required <code>attrname</code> <code>str</code> <p>The attribute name to access the RateSemaphore belonging to the object instance. Defaults to \"rate_semaphore\".</p> <code>'rate_semaphore'</code> <code>verbose</code> <code>bool</code> <p>Whether to print verbose transaction information. Defaults to True.</p> <code>False</code> <p>Returns:</p> Type Description <code>any</code> <p>The return value of the decorated method.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the instance does not have the specified attribute or if costs is less than 0.</p>"},{"location":"throttler/decorators/#quantpylib.throttler.decorators.wrap_in_thread","title":"<code>wrap_in_thread(_func=None, *, costs, refund_in, attrname='rate_semaphore', daemon=False, verbose=True)</code>","text":"<p>Decorator to wrap a synchronous instance-level method into a transaction, and that transaction into a thread.  The return value is a thread, that is not yet alive, and can be activated by invoking the  <code>threading.Thread.start</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>_func</code> <code>callable</code> <p>The function to be wrapped.</p> <code>None</code> <code>costs</code> <code>float</code> <p>The number of credits required for the transaction.</p> required <code>refund_in</code> <code>float</code> <p>The time in seconds after which the credits should be refunded.</p> required <code>attrname</code> <code>str</code> <p>The attribute name to access the RateSemaphore belonging to the object instance. Defaults to \"rate_semaphore\".</p> <code>'rate_semaphore'</code> <code>daemon</code> <code>bool</code> <p>Whether the thread should be a daemon thread. Defaults to False.</p> <code>False</code> <code>verbose</code> <code>bool</code> <p>Whether to print verbose transaction information. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>Thread</code> <p>The thread with the transaction as target function, where the transaction wraps the decorated function. Not yet alive.</p> <p>Raises:</p> Type Description <code>AssertionError</code> <p>If the instance does not have the specified attribute or if costs is less than 0.</p>"},{"location":"throttler/rate_semaphore/","title":"quantpylib.throttler.rate_semaphore","text":"<p><code>quantpylib.throttler.rate_semaphore</code> is our core rate-limiting and throttling module, and exposes two synchronization tools, the  <code>quantpylib.throttler.rate_semaphore.AsyncRateSemaphore</code> and <code>quantpylib.throttler.rate_semaphore.RateSemaphore</code> classes.</p> <p>Instead of having to write server-dependent code on rate-limiting based on error messages and response headers (say, of a HTTP 429 response), the rate-semaphores make rate-limiting on the client side seamless and easy  by wrapping native Python objects and synchronization primitives. Any Python  function can be rate-limited (with <code>RateSemaphore</code>) and any Python coroutine  can be rate-limited (with <code>AsyncRateSemaphore</code>) by submitting transactions to the semaphores through the <code>transact</code> method. The module is flexible enough to handle both fixed-cost endpoints (specs such as '20 API requests/min') or  variable-cost endpoints (specs such as `5 API credits/getTick', '15 API credits/getOHLCV' with '100 credits/min per client').</p> <p>Users would likely only have to interact with the <code>transact</code> method in both classes to use the synchronization features. Additionally, users may opt to decorate request-functions with our <code>quantpylib.throttler.decorators</code> on instance methods that makes interacting with the semaphores a one-liner.</p> <p>Examples for both decorator usage, and synchronous, asynchronous semaphores are given here.</p>"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.AsyncRateSemaphore","title":"<code>AsyncRateSemaphore</code>","text":"<p>An asynchronous semaphore implementation that limits access to coroutines (known as transactions) based on available credits, and manages credit-debit accounting of a common resource pool. Coroutines to be executed are submitted to the <code>AsyncRateSemaphore.transact</code>  method along with the number of credits it consumes and the time it takes for those credits to be refunded to the resource pool.  Can be used to throttle asynchronous work such as non-blocking API requests or database operations. In most cases, users would only need to interact with the <code>AsyncRateSemaphore.transact</code> method.</p>"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.AsyncRateSemaphore.__init__","title":"<code>__init__(credits=1, greedy_entry=False, greedy_exit=True)</code>","text":"<p>Initialize the <code>AsyncRateSemaphore</code> with an initial number of credits.</p> <p>Parameters:</p> Name Type Description Default <code>credits</code> <code>float</code> <p>The initial number of credits the semaphore starts with. Defaults to 1.</p> <code>1</code> <code>greedy_entry</code> <code>bool</code> <p>Determines whether to enforce a FIFO or greedy policy for pending coroutines                             on semaphore entry. Defaults to False.</p> <code>False</code> <code>greedy_exit</code> <code>bool</code> <p>Determines whether to enforce a FIFO or greedy policy for waking up pending coroutines                             on credit refund. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>credits</code> is less than 0.</p>"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.AsyncRateSemaphore.acquire","title":"<code>acquire(require_credits, refund_time)</code>  <code>async</code>","text":"<p>Acquire the semaphore, decrementing the resource pool by specified number of credits. If the existing resource pool is larger than credits required, decrement the credits and return immediately. If there is not enough credits on entry, do a non-blocking wait until enough resources are freed up. Additionally, if <code>greedy_entry=False</code>, then  the executing transaction will wait behind the earlier pending transactions regardless of the resource  pool availability.</p> <p>Parameters:</p> Name Type Description Default <code>require_credits</code> <code>float</code> <p>The number of credits required to enter the semaphore.</p> required <code>refund_time</code> <code>float</code> <p>The time in seconds after which the credits should be refunded.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True when the credits were successfully acquired.</p>"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.AsyncRateSemaphore.release","title":"<code>release(taken_credits)</code>","text":"<p>Refund the specified number of credits and wake up pending transactions that  are able to execute on the state of the resource pool. Additionally, if <code>greedy_exit=False</code>, then the number of pending transactions  woken up will respect the FIFO order until the resource pool is insufficient for the earliest transaction.</p> <p>Parameters:</p> Name Type Description Default <code>taken_credits</code> <code>float</code> <p>The number of credits to release.</p> required"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.AsyncRateSemaphore.transact","title":"<code>transact(coroutine, credits, refund_time, transaction_id=None, verbose=False)</code>  <code>async</code>","text":"<p>Execute an asynchronous coroutine object using the semaphore for synchronization, utilizing the <code>AsyncRateSemaphore.acquire</code> and <code>AsyncRateSemaphore.release</code> methods for proper synchronization. The refund mechanism is scheduled on the running event loop and the transact method returns without waiting for credits to be refunded. Failed transactions (raised Exceptions) consume and refund credit in the same way as successful transactions.</p> <p>Parameters:</p> Name Type Description Default <code>coroutine</code> <code>coroutine function</code> <p>The coroutine to execute as part of the transaction.</p> required <code>credits</code> <code>float</code> <p>The number of credits required for the transaction.</p> required <code>refund_time</code> <code>float</code> <p>The time in seconds after which the credits should be refunded.</p> required <code>transaction_id</code> <code>str</code> <p>Identifier for the transaction. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to print verbose transaction information. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>The result of the executed coroutine.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the coroutine raises any exception.</p> Notes <p>The argument <code>coroutine</code> should NOT be a <code>asyncio.Task</code> object, since any <code>await</code> statements will trigger  its execution on the event loop before the semaphore is acquired.</p>"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.RateSemaphore","title":"<code>RateSemaphore</code>","text":"<p>A semaphore implementation that limits the access to method/requests (known as transactions) based on available credits, and manages credit-debit accounting of a common resource pool. Functions to be executed are submitted to the <code>RateSemaphore.transact</code>  method along with the number of credits it consumes and the time it takes for those credits to be refunded to the resource pool. Can be used to throttle API requests, database operations and so on. In most cases, the user would only need to interact with the  <code>RateSemaphore.transact</code> method.</p>"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.RateSemaphore.__init__","title":"<code>__init__(credits=1)</code>","text":"<p>Initialize the <code>RateSemaphore</code> with an initial number of credits.</p> <p>Parameters:</p> Name Type Description Default <code>credits</code> <code>float</code> <p>The initial number of credits the semaphore starts with. Defaults to 1.</p> <code>1</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>credits</code> is less than 0.</p>"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.RateSemaphore.acquire","title":"<code>acquire(require_credits)</code>","text":"<p>Acquire the semaphore, decrementing the resource pool by specified number of credits. If the existing resource pool is larger than credits required, decrement the credits and return immediately. If there is not enough credits on entry, block, waiting until  some other thread has called release() until enough resources are freed up. This is done with proper interlocking so that if multiple acquire() calls are blocked,  release() will wake exactly one of them up. The implementation may pick one at random,  so the order in which blocked threads are awakened should not be relied  on and is OS-scheduler dependent.</p> <p>Parameters:</p> Name Type Description Default <code>require_credits</code> <code>float</code> <p>The number of credits required to enter the semaphore.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True when the credits were successfully acquired.</p>"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.RateSemaphore.release","title":"<code>release(taken_credits)</code>","text":"<p>Refund the specified number of credits.</p> <p>Parameters:</p> Name Type Description Default <code>taken_credits</code> <code>float</code> <p>The number of credits to release.</p> required"},{"location":"throttler/rate_semaphore/#quantpylib.throttler.rate_semaphore.RateSemaphore.transact","title":"<code>transact(lambda_func, credits, refund_time, transaction_id=None, verbose=False)</code>","text":"<p>Execute a parameter-less function using the semaphore for synchronization, using the <code>RateSemaphore.acquire</code> and <code>RateSemaphore.release</code> methods for proper synchronization. The refund mechanism is scheduled in a worker  thread and the transact method returns without waiting for credits to be refunded. Failed transactions (raised Exceptions) consume and refund credit in the same way as successful transactions.</p> <p>Parameters:</p> Name Type Description Default <code>lambda_func</code> <code>callable</code> <p>The function to execute as part of the transaction. Should not take in any parameters.</p> required <code>credits</code> <code>float</code> <p>The number of credits required for the transaction.</p> required <code>refund_time</code> <code>float</code> <p>The time in seconds after which the credits should be refunded.</p> required <code>transaction_id</code> <code>str</code> <p>Identifier for the transaction. Defaults to None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to print verbose transaction information. Defaults to False.</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Any</code> <p>The result of the transaction function.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the transaction function raises any exception.</p> Notes <p>Any function <code>func</code> that takes in <code>*args</code>, <code>**kwargs</code> can easily be used with  the semaphore by passing in <code>lambda_func = lambda : func(*args,**kwargs)</code>.</p>"},{"location":"throttler/throttler/","title":"throttler","text":"<p>This page describes how you may use our <code>quantpylib.throttler</code> module and the functionalities exposed by our APIs. This module provides both synchronous and asynchronous support for rate-limiting access to function calls via a credit-based  semaphore synchronization tool. A simple but common use would be to maximise throughput of API requests to an external server that places rate-limits on the number of API requests per minute/hour with request credits charged against a resource pool. This is made available by the <code>quantpylib.throttler.rate_semaphore</code> module through  the <code>RateSemaphore</code> and <code>AsyncRateSemaphore</code> classes - and can be seen as an extension of the synchronization  primitives <code>threading.Semaphore</code> and <code>asyncio.locks.Semaphore</code> in the Python standard library respectively. The <code>quantpylib.throttler.decorators</code> module provides decorators for instance methods that wraps threads and coroutines to provide seamless integration with the synchronization features.</p> <p>A high-level walkthrough of the individual quant packages are presented in this page. Comprehensive documentation may be found in the respective pages. To follow along, make sure you have installed the necessary dependencies. Code example scripts are also provided in the repo.</p> <p>The module is flexible enough to handle both fixed-cost endpoints (specs such as '20 API requests/min') or  variable-cost endpoints (specs such as `5 API credits/getTick', '15 API credits/getOHLCV' with '100 credits/min per client').</p>"},{"location":"throttler/throttler/#examples","title":"Examples","text":"<p>Suppose we have a financial API endpoint that has rate limits as such:</p> Period Credits Awarded / app 10 seconds 40 <p>The API gives us 40 credits to use every 10 seconds (capped at 40 credits max). Different endpoints can have variable credit costs, depending on the server load. </p> <p>Suppose we have the following endpoints and their respective costs:</p> Endpoint Cost (credits / req) getTick 20 getOHLCV 5..30 getPrice 12.5 ... ... <p>Both synchronous and asynchronous semaphores expose their synchronization features through the <code>semaphore.transact(...)</code> method, which have the same function signature, except  that the first parameter to a synchronous transaction is a parameter-less function, and the first parameter to the asynchronous transaction is a coroutine. Their detailed documentations are defined here.</p> <p>For the demonstration, we require the following imports: <pre><code>import time\nimport random\nimport asyncio\nimport threading\n\nfrom datetime import datetime\nfrom quantpylib.throttler.decorators import wrap_in_thread, aconsume_credits\nfrom quantpylib.throttler.rate_semaphore import RateSemaphore,AsyncRateSemaphore\n</code></pre></p>"},{"location":"throttler/throttler/#synchronous-example","title":"Synchronous Example","text":"<p>Let's begin with the example for the synchronous semaphore, given by the <code>RateSemaphore</code> class. Our objective is to maximise the throughput to a bunch of blocking requests that consume credits on some external server. To simulate blocking requests, such as a <code>requests.get</code> method, we use the <code>time.sleep</code> method. Note that this generalizes to any blocking method. <pre><code>def getTick(work, id):\n    print(f\"{datetime.now()}:: getTick processing {id} takes {work} seconds\")\n    time.sleep(work)\n    print(f\"{datetime.now()}:: getTick processed {id}\")\n    return True\n\ndef getOHLCV(work, id):\n    print(f\"{datetime.now()}:: getOHLCV processing {id} takes {work} seconds\")\n    time.sleep(work)\n    print(f\"{datetime.now()}:: getOHLCV processed {id}\")\n    return True\n</code></pre></p> <p>Since we want to maximise throughput, and the function calls block the main thread, we want to create the requests in multiple threads. But since sending all of these requests simultaneously in different threads would overload the market data server (giving us errors/downgraded/blacklisted), we would wrap them in rate-limited transactions and submit them to the semaphore. Let's create some script to run some requests through the semaphore with the <code>transact</code> method : <pre><code>def sync_example():\n    print(\"-----------------------sync with thread-----------------------\")\n    sem = RateSemaphore(40)\n    tick_req = lambda x: getTick(random.randint(1, 5), x)\n    ohlcv_req = lambda x: getOHLCV(random.randint(1, 5), x)\n\n    threads = [\n        threading.Thread(target=sem.transact,kwargs={\n            \"lambda_func\":lambda: tick_req(1), \n            \"credits\":20, \n            \"refund_time\":10, \n            \"transaction_id\":1, #optional\n            \"verbose\":True #optional\n        }),\n        threading.Thread(target=sem.transact,kwargs={\n            \"lambda_func\":lambda: ohlcv_req(2), \n            \"credits\":30, \n            \"refund_time\":10, \n            \"transaction_id\":2, #optional\n            \"verbose\":True #optional\n        }),\n        threading.Thread(target=sem.transact,kwargs={\n            \"lambda_func\":lambda: ohlcv_req(3), \n            \"credits\":5, \n            \"refund_time\":10, \n            \"transaction_id\":3, \n            \"verbose\":True\n        }),\n        threading.Thread(target=sem.transact,kwargs={\n            \"lambda_func\":lambda: tick_req(4), \n            \"credits\":20, \n            \"refund_time\":10, \n            \"transaction_id\":4, \n            \"verbose\":True\n        }),\n    ]\n    [thread.start() for thread in threads]\n    [thread.join() for thread in threads]\n\nif __name__ == \"__main__\":\n    sync_example()\n</code></pre> We set the verbosity flag to give us information on when the semaphore executed the transactions, so let us observe the printed information log: <pre><code>-----------------------sync with thread-----------------------\n2024-03-28 19:16:27.105953:: TXN 1 acquiring CreditSemaphore\n2024-03-28 19:16:27.106051:: TXN 2 acquiring CreditSemaphore\n2024-03-28 19:16:27.106083:: TXN 1 entered CreditSemaphore...\n2024-03-28 19:16:27.106161:: TXN 3 acquiring CreditSemaphore\n2024-03-28 19:16:27.106303:: TXN 4 acquiring CreditSemaphore\n2024-03-28 19:16:27.106367:: TXN 3 entered CreditSemaphore...\n2024-03-28 19:16:27.106426:: getOHLCV processing 3 takes 4 seconds\n2024-03-28 19:16:27.106449:: getTick processing 1 takes 5 seconds\n2024-03-28 19:16:31.106689:: getOHLCV processed 3\n2024-03-28 19:16:31.106877:: TXN 3 exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:16:32.107982:: getTick processed 1\n2024-03-28 19:16:32.108390:: TXN 1 exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:16:41.109162:: TXN 4 entered CreditSemaphore...\n2024-03-28 19:16:41.109260:: getTick processing 4 takes 2 seconds\n2024-03-28 19:16:43.110862:: getTick processed 4\n2024-03-28 19:16:43.111243:: TXN 4 exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:16:53.113011:: TXN 2 entered CreditSemaphore...\n2024-03-28 19:16:53.113060:: getOHLCV processing 2 takes 3 seconds\n2024-03-28 19:16:56.115643:: getOHLCV processed 2\n2024-03-28 19:16:56.115815:: TXN 2 exits CreditSemaphore, schedule refund in 10...\n</code></pre> It is not difficult to reason with the output. For instance, transactions 1 and 3 entered the semaphore first, while 2, 4 was placed on hold, leaving 40 - 20 - 5 = 15 credits. No other transaction can enter the semaphore. Transaction 3 processes and completes at 31 seconds,  but the credit is only refunded 10 seconds later. We can see that at 41 seconds, the (5) credits from transaction 3 is refunded, giving us 15 + 5 = 20 credits, enough for transaction 4 to enter the semaphore but not 2. The rest of printed log statements are easy to rationalize.</p>"},{"location":"throttler/throttler/#easy-with-decorators","title":"Easy with Decorators","text":"<p>The example given is nice but somewhat unwiedly due to having to wrap the method/function of interest first in a semaphore  transaction, then followed by a <code>threading.Thread</code> object. In many software applications, we have a data-service layer with a poller object/SDK for API calls made to  external servers. A simulated example looks something like this:</p> <p><pre><code>class _Throttler():\n    def __init__(self):\n        self.rate_semaphore=RateSemaphore(31)\n\n    @wrap_in_thread(costs=20,refund_in=10)#,attrname=\"rate_semaphore\",verbose=True (optional-defaults)\n    def _getTick(self, work, id):\n        print(f\"{datetime.now()}:: getTick processing {id} takes {work} seconds\")\n        time.sleep(work)\n        print(f\"{datetime.now()}:: getTick processed {id}\")\n        return True\n\n    @wrap_in_thread(costs=10,refund_in=10,attrname=\"rate_semaphore\",verbose=True)\n    def _getOHLCV(self, work, id):\n        print(f\"{datetime.now()}:: getOHLCV processing {id} takes {work} seconds\")\n        time.sleep(work)\n        print(f\"{datetime.now()}:: getOHLCV processed {id}\")\n        return True\n</code></pre> The data-access object is given one or more <code>RateSemaphore</code>  objects corresponding to a unique credit/resource pool. For each  method that makes a resource-consuming request, we can decorate the function using <code>wrap_in_thread</code> with the costs and refund timers as parameters. The decorated function calls then directly return <code>threading.Thread</code> instances wrapping transactions that contain the function request, which can be activated using the <code>threading.Thread.start</code> method. <pre><code>def sync_example():\n    print(\"-----------------------sync with thread-----------------------\")\n    #... previous example\n\n    print(\"-----------------------sync with decorator-----------------------\")\n    throttler = _Throttler()\n    threads = [\n        throttler._getTick(3, 1),\n        throttler._getOHLCV(1, 2),\n        throttler._getTick(3, 3),\n        throttler._getOHLCV(1, 4),\n    ]\n    [thread.start() for thread in threads]\n    [thread.join() for thread in threads]\n</code></pre> The behavior of the semaphore is similar to the example explored in the previous example.  The printed log statements are hence presented without commentary, but may be rationalized easily. <pre><code>----------------------sync with decorator-----------------------\n2024-03-28 19:16:56.116058:: TXN {'fn': '_getTick', 'args': (3, 1), 'kwargs': {}} acquiring CreditSemaphore\n2024-03-28 19:16:56.116154:: TXN {'fn': '_getOHLCV', 'args': (1, 2), 'kwargs': {}} acquiring CreditSemaphore\n2024-03-28 19:16:56.116220:: TXN {'fn': '_getTick', 'args': (3, 1), 'kwargs': {}} entered CreditSemaphore...\n2024-03-28 19:16:56.116302:: TXN {'fn': '_getTick', 'args': (3, 3), 'kwargs': {}} acquiring CreditSemaphore\n2024-03-28 19:16:56.116555:: getTick processing 1 takes 3 seconds\n2024-03-28 19:16:56.116366:: TXN {'fn': '_getOHLCV', 'args': (1, 2), 'kwargs': {}} entered CreditSemaphore...\n2024-03-28 19:16:56.116515:: TXN {'fn': '_getOHLCV', 'args': (1, 4), 'kwargs': {}} acquiring CreditSemaphore\n2024-03-28 19:16:56.116691:: getOHLCV processing 2 takes 1 seconds\n2024-03-28 19:16:57.120664:: getOHLCV processed 2\n2024-03-28 19:16:57.120879:: TXN {'fn': '_getOHLCV', 'args': (1, 2), 'kwargs': {}} exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:16:59.117150:: getTick processed 1\n2024-03-28 19:16:59.117323:: TXN {'fn': '_getTick', 'args': (3, 1), 'kwargs': {}} exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:17:07.123469:: TXN {'fn': '_getOHLCV', 'args': (1, 4), 'kwargs': {}} entered CreditSemaphore...\n2024-03-28 19:17:07.123532:: getOHLCV processing 4 takes 1 seconds\n2024-03-28 19:17:08.125678:: getOHLCV processed 4\n2024-03-28 19:17:08.126219:: TXN {'fn': '_getOHLCV', 'args': (1, 4), 'kwargs': {}} exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:17:09.118384:: TXN {'fn': '_getTick', 'args': (3, 3), 'kwargs': {}} entered CreditSemaphore...\n2024-03-28 19:17:09.118482:: getTick processing 3 takes 3 seconds\n2024-03-28 19:17:12.119387:: getTick processed 3\n2024-03-28 19:17:12.119741:: TXN {'fn': '_getTick', 'args': (3, 3), 'kwargs': {}} exits CreditSemaphore, schedule refund in 10...\n</code></pre></p>"},{"location":"throttler/throttler/#asynchronous-example","title":"Asynchronous Example","text":"<p>We now move onto the asynchronous semaphore, given by the <code>AsyncRateSemaphore</code> class. Our objective is to maximise the throughput to a bunch of non-blocking requests that consume credits on some external server. To simulate non-blocking requests, such as an  <code>async with session.get</code> method of an <code>aiohttp.ClientSession</code> object or asynchronous database requests, we use the  <code>asyncio.sleep</code> method. Note that this generalizes to any non-blocking coroutine.</p> <pre><code>async def agetTick(work, id):\n    print(f\"{datetime.now()}:: getTick processing {id} takes {work} seconds\")\n    await asyncio.sleep(work)\n    print(f\"{datetime.now()}:: getTick processed {id}\")\n    return True\n\nasync def agetOHLCV(work, id):\n    print(f\"{datetime.now()}:: getOHLCV processing {id} takes {work} seconds\")\n    await asyncio.sleep(work)\n    print(f\"{datetime.now()}:: getOHLCV processed {id}\")\n    return True\n</code></pre> <p>Since we want to maximise throughput, and the function calls are coroutines that do not block  the main thread, we want to create the requests concurrently and place them on the event loop. But since sending all of these requests simultaneously in different coroutines would overload the market data server (giving us errors/downgraded/blacklisted), we would wrap them in rate-limited transactions and submit them to the semaphore. Let's create some script to run some request transactions through the semaphore:</p> <p><pre><code>async def async_example():\n    print(\"-----------------------async with transactions-----------------------\")\n    sem = AsyncRateSemaphore(40, greedy_entry=True, greedy_exit=True)\n\n    tick_req = lambda x: agetTick(random.randint(1, 5), x)\n    ohlcv_req = lambda x: agetOHLCV(random.randint(1, 5), x)\n\n    transactions = [\n        sem.transact(coroutine=tick_req(1), credits=20, refund_time=10, transaction_id=1, verbose=True),\n        sem.transact(coroutine=ohlcv_req(2), credits=30, refund_time=10, transaction_id=2, verbose=True),\n        sem.transact(coroutine=ohlcv_req(3), credits=5, refund_time=10, transaction_id=3, verbose=True),\n        sem.transact(coroutine=tick_req(4), credits=20, refund_time=10, transaction_id=4, verbose=True),\n    ]\n    await asyncio.gather(*transactions)\n\nif __name__ == \"__main__\":\n    sync_example() #previous example\n    asyncio.run(async_example())\n</code></pre> We set the verbosity flag to give us information on when the semaphore executed the transactions, so let us observe the printed information log: <pre><code>-----------------------async with transactions-----------------------\n2024-03-28 19:17:12.120864:: TXN 1 acquiring CreditSemaphore\n2024-03-28 19:17:12.120915:: TXN 1 entered CreditSemaphore...\n2024-03-28 19:17:12.120927:: getTick processing 1 takes 4 seconds\n2024-03-28 19:17:12.120964:: TXN 2 acquiring CreditSemaphore\n2024-03-28 19:17:12.120988:: TXN 3 acquiring CreditSemaphore\n2024-03-28 19:17:12.121006:: TXN 3 entered CreditSemaphore...\n2024-03-28 19:17:12.121016:: getOHLCV processing 3 takes 5 seconds\n2024-03-28 19:17:12.121044:: TXN 4 acquiring CreditSemaphore\n2024-03-28 19:17:16.121665:: getTick processed 1\n2024-03-28 19:17:16.121740:: TXN 1 exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:17:17.122353:: getOHLCV processed 3\n2024-03-28 19:17:17.122462:: TXN 3 exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:17:26.123119:: TXN 2 entered CreditSemaphore...\n2024-03-28 19:17:26.123192:: getOHLCV processing 2 takes 1 seconds\n2024-03-28 19:17:27.123519:: getOHLCV processed 2\n2024-03-28 19:17:27.123633:: TXN 2 exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:17:37.124999:: TXN 4 entered CreditSemaphore...\n2024-03-28 19:17:37.125077:: getTick processing 4 takes 3 seconds\n2024-03-28 19:17:40.126377:: getTick processed 4\n2024-03-28 19:17:40.126493:: TXN 4 exits CreditSemaphore, schedule refund in 10...\n</code></pre> It is not difficult to reason with the output. For instance, transactions 1 and 3 entered the semaphore first, while 2, 4 was placed on hold, leaving 40 - 20 - 5 = 15 credits. No other transaction can enter the semaphore. Transaction 1 processes and completes at 16 seconds,  but the credit is only refunded 10 seconds later. We can see that at 26 seconds, the (20) credits from transaction 1 is refunded, giving us 15 + 20 = 35 credits, enough for transaction 2 to enter the semaphore but not both 2 and 4. 2 is admitted first, and the rest of printed log statements are easy to rationalize.</p>"},{"location":"throttler/throttler/#easy-with-decorators_1","title":"Easy with Decorators","text":"<p>The example given is nice but somewhat unwiedly due to having to wrap the method/function of interest in semaphore transactions. We would like to hide  the throttling intricacies at the caller level, such that a user of said data-access layer  or SDKs do not need to be aware of the presence of a semaphore. For instance: <pre><code>class _Throttler():\n    def __init__(self):\n        #... previous example\n        self.arate_semaphore=AsyncRateSemaphore(31)\n\n    #... previous example\n\n    @aconsume_credits(costs=20,refund_in=10,attrname=\"arate_semaphore\") #we want the asynchronous semaphore, and since the default name is not rate_semaphore, we pass in attrname\n    async def _agetTick(self, work, id):\n        print(f\"{datetime.now()}:: getTick processing {id} takes {work} seconds\")\n        await asyncio.sleep(work)\n        print(f\"{datetime.now()}:: getTick processed {id}\")\n        return True\n\n    @aconsume_credits(costs=10,refund_in=10,attrname=\"arate_semaphore\",verbose=True)\n    async def _agetOHLCV(self, work, id):\n        print(f\"{datetime.now()}:: getOHLCV processing {id} takes {work} seconds\")\n        await asyncio.sleep(work)\n        print(f\"{datetime.now()}:: getOHLCV processed {id}\")\n        return True\n</code></pre> The data-access object is given one or more <code>AsyncRateSemaphore</code> objects corresponding to a unique credit/resource pool. For each  method that makes a resource-consuming request, we can decorate the function using <code>aconsume_credits</code> with the costs and refund timers as parameters. The decorated function calls then are submitted through the object attribute's asynchronous semaphore instance. <pre><code>async def async_example():\n    print(\"-----------------------async with transactions-----------------------\")\n    #... previous example\n\n    print(\"-----------------------async with decorator-----------------------\")\n    throttler = _Throttler()\n    transactions = [\n        throttler._agetTick(3, 1),\n        throttler._agetOHLCV(1, 2),\n        throttler._agetTick(3, 3),\n        throttler._agetOHLCV(1, 4),\n    ]\n    await asyncio.gather(*transactions)\n</code></pre> The behavior of the semaphore is similar to the example explored in the previous example.  The printed log statements are hence presented without commentary, but may be rationalized easily. <pre><code>-----------------------async with decorator-----------------------\n2024-03-28 19:17:40.126936:: TXN {'fn': '_agetTick', 'args': (3, 1), 'kwargs': {}} acquiring CreditSemaphore\n2024-03-28 19:17:40.127015:: TXN {'fn': '_agetTick', 'args': (3, 1), 'kwargs': {}} entered CreditSemaphore...\n2024-03-28 19:17:40.127044:: getTick processing 1 takes 3 seconds\n2024-03-28 19:17:40.127110:: TXN {'fn': '_agetOHLCV', 'args': (1, 2), 'kwargs': {}} acquiring CreditSemaphore\n2024-03-28 19:17:40.127149:: TXN {'fn': '_agetOHLCV', 'args': (1, 2), 'kwargs': {}} entered CreditSemaphore...\n2024-03-28 19:17:40.127170:: getOHLCV processing 2 takes 1 seconds\n2024-03-28 19:17:40.127217:: TXN {'fn': '_agetTick', 'args': (3, 3), 'kwargs': {}} acquiring CreditSemaphore\n2024-03-28 19:17:40.127266:: TXN {'fn': '_agetOHLCV', 'args': (1, 4), 'kwargs': {}} acquiring CreditSemaphore\n2024-03-28 19:17:41.127912:: getOHLCV processed 2\n2024-03-28 19:17:41.128021:: TXN {'fn': '_agetOHLCV', 'args': (1, 2), 'kwargs': {}} exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:17:43.127485:: getTick processed 1\n2024-03-28 19:17:43.127539:: TXN {'fn': '_agetTick', 'args': (3, 1), 'kwargs': {}} exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:17:51.129270:: TXN {'fn': '_agetOHLCV', 'args': (1, 4), 'kwargs': {}} entered CreditSemaphore...\n2024-03-28 19:17:51.129314:: getOHLCV processing 4 takes 1 seconds\n2024-03-28 19:17:52.130482:: getOHLCV processed 4\n2024-03-28 19:17:52.130534:: TXN {'fn': '_agetOHLCV', 'args': (1, 4), 'kwargs': {}} exits CreditSemaphore, schedule refund in 10...\n2024-03-28 19:17:53.128193:: TXN {'fn': '_agetTick', 'args': (3, 3), 'kwargs': {}} entered CreditSemaphore...\n2024-03-28 19:17:53.128281:: getTick processing 3 takes 3 seconds\n2024-03-28 19:17:56.129573:: getTick processed 3\n2024-03-28 19:17:56.129683:: TXN {'fn': '_agetTick', 'args': (3, 3), 'kwargs': {}} exits CreditSemaphore, schedule refund in 10...\n</code></pre></p>"},{"location":"throttler/throttler/#notes-on-behavior","title":"Notes on Behavior","text":"<ul> <li> <p> Entry Behavior  </p> <ol> <li><code>AsyncRateSemaphore</code> acquires the semaphore if there are enough resources, but if <code>greedy_entry=False</code>, then the submitted transaction will wait behind the earlier pending transactions regardless of the resource pool availability. Otherwise, any submitted transaction that can run immediately will run without consideration for existing waiters.</li> <li><code>RateSemaphore</code> acquires the semaphore immediately if there are enough resources, and  otherwise waits. The order in which blocked threads are awakened should not be relied on and is OS-scheduler dependent.</li> </ol> </li> <li> <p> Exit Behavior   Requests submitted to both semaphore types exit from their respective <code>transact</code> method without waiting for the credits to be refunded. The credits are scheduled to be refunded separately on a thread (for synchronous implementations) or the event loop (for asynchronous implementations). When the credit is refunded </p> <ol> <li> <p><code>AsyncRateSemaphore</code> wakes up pending transactions that are able to execute on the state of the resource pool. If <code>greedy_exit=False</code>, then the number of pending transactions woken up will respect the FIFO order until the resource pool is insufficient for the earliest transaction. Otherwise, when credits are refunded with &gt;=2 waiting transactions with arrival time <code>txn A</code> &lt; <code>txn B</code>. If the semaphore has not enough credits to execute <code>txn A</code>, it can first run <code>txn B</code>. This helps to maximise throughput.</p> </li> <li> <p><code>RateSemaphore</code> wakes up pending transactions that are able to execute on the state of the resource pool. The order in which blocked threads are awakened should not be relied on and is OS-scheduler dependent.</p> </li> </ol> </li> <li> <p> Exception Behavior   Failed transactions (raised Exceptions) consume and refund credit in the same way as successful transactions.</p> </li> </ul>  Note that non-greedy entry and greedy exit can cause resource-expensive transactions to sit behind cheaper transactions which are constantly being submitted to the semaphore at a fast rate, preventing the expensive transaction from acquiring the semaphore."},{"location":"throttler/throttler/#best-practices","title":"Best Practices","text":"<ul> <li> <p>Wrap unstable networks and expensive requests in a timeout transaction. This is to prevent the coroutine from 'await'-ing forever and hogging the semaphore.</p> </li> <li> <p>Since the transactions wrap native Python functions and coroutines, it does not know when the code actually performs the credit-costing request. The <code>transact</code> functions should be closest to the costful logic as possible. It should not perform heavy compute or multiple requests so that the credits can refunded as quickly as possible for other transactions. </p> </li> </ul>"},{"location":"throttler/throttler/#throttlerratesemaphore","title":"throttler.rate_semaphore","text":""},{"location":"throttler/throttler/#throttlerratedecorator","title":"throttler.decorators","text":""},{"location":"wrappers/binance/","title":"quantpylib.wrappers.binance","text":""},{"location":"wrappers/binance/#quantpylib.wrappers.binance.Binance","title":"<code>Binance</code>","text":""},{"location":"wrappers/binance/#quantpylib.wrappers.binance.Binance.__init__","title":"<code>__init__()</code>","text":"<p>Initialize the Binance instance with the Binance exchange client and rate limiter.</p> Read <p>https://binance-docs.github.io/apidocs/spot/en/#limits</p>"},{"location":"wrappers/binance/#quantpylib.wrappers.binance.Binance.get_exchange_server_timestamp","title":"<code>get_exchange_server_timestamp(**kwargs)</code>","text":"<p>Retrieve the server timestamp from the Binance exchange.</p> <p>Returns:</p> Name Type Description <code>int</code> <p>The server timestamp from the Binance exchange.</p>"},{"location":"wrappers/binance/#quantpylib.wrappers.binance.Binance.get_ticker_metadata","title":"<code>get_ticker_metadata(ticker, **kwargs)</code>","text":"<p>Retrieve metadata for the specified ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The trading instrument ticker.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Metadata for the specified ticker.</p>"},{"location":"wrappers/binance/#quantpylib.wrappers.binance.Binance.get_tickers_in_exchange","title":"<code>get_tickers_in_exchange(**kwargs)</code>","text":"<p>Retrieve the collection of tickers available in the Binance exchange.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary of tickers available in the Binance exchange.</p>"},{"location":"wrappers/binance/#quantpylib.wrappers.binance.Binance.get_trade_bars","title":"<code>get_trade_bars(ticker, start, end, granularity, granularity_multiplier, **kwargs)</code>","text":"<p>Retrieve OHLCV trade bar data for the specified ticker and time range.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The trading instrument ticker.</p> required <code>start</code> <code>datetime</code> <p>The start date and time for data retrieval.</p> required <code>end</code> <code>datetime</code> <p>The end date and time for data retrieval.</p> required <code>granularity</code> <code>Period</code> <p>The period type for the OHLCV bars.</p> required <code>granularity_multiplier</code> <code>int</code> <p>The granularity multiplier.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: The OHLCV trade bar data for the specified ticker and time range.</p>"},{"location":"wrappers/ccxt/","title":"quantpylib.wrappers.ccxt","text":""},{"location":"wrappers/eodhd/","title":"quantpylib.wrappers.eodhd","text":""},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd","title":"<code>Eodhd</code>","text":""},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.__init__","title":"<code>__init__(eod_key)</code>","text":"<p>Initialize the Eodhd instance with the API key.</p> <p>Parameters:</p> Name Type Description Default <code>eod_key</code> <code>str</code> <p>API key for accessing the Eodhd API.</p> required"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.check_exchange_open","title":"<code>check_exchange_open(exchange, **kwargs)</code>","text":"<p>Check if a specific exchange is open.</p> <p>Parameters:</p> Name Type Description Default <code>exchange</code> <code>str</code> <p>Exchange name.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if the exchange is open, False otherwise.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.close_market_data_stream","title":"<code>close_market_data_stream(ticker, endpoint, **kwargs)</code>  <code>async</code>","text":"<p>Terminate stream for ticker data.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol for the asset.</p> required <code>endpoint</code> <p>Endpoint for streaming. Valid values are: <code>[\"us\", \"us-quote\", \"forex\", \"crypto\"]</code>.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_delisted_tickers_in_exchange","title":"<code>get_delisted_tickers_in_exchange(exchange, **kwargs)</code>","text":"<p>Get the list of delisted tickers for a specific exchange.</p> <p>Parameters:</p> Name Type Description Default <code>exchange</code> <code>str</code> <p>Exchange name.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the list of delisted tickers for the exchange.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_exchange_holidays","title":"<code>get_exchange_holidays(exchange, **kwargs)</code>","text":"<p>Get the list of holidays for a specific exchange.</p> <p>Parameters:</p> Name Type Description Default <code>exchange</code> <code>str</code> <p>Exchange name.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the list of holidays for the exchange.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_exchange_hours","title":"<code>get_exchange_hours(exchange, **kwargs)</code>","text":"<p>Get the trading hours for a specific exchange.</p> <p>Parameters:</p> Name Type Description Default <code>exchange</code> <code>str</code> <p>Exchange name.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Trading hours for the exchange.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_exchange_tz","title":"<code>get_exchange_tz(exchange, **kwargs)</code>","text":"<p>Get the timezone for a specific exchange.</p> <p>Parameters:</p> Name Type Description Default <code>exchange</code> <code>str</code> <p>Exchange name.</p> required <p>Returns:</p> Name Type Description <code>str</code> <p>Timezone of the exchange.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_supported_exchanges","title":"<code>get_supported_exchanges(**kwargs)</code>","text":"<p>Get the list of supported exchanges.</p> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the list of supported exchanges.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_dividends","title":"<code>get_ticker_dividends(ticker, exchange, **kwargs)</code>","text":"<p>Retrieve dividend data for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing dividend data for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_earnings_history","title":"<code>get_ticker_earnings_history(ticker, exchange='US', **kwargs)</code>","text":"<p>Retrieve earnings history data for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing earnings history data for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_earnings_trend","title":"<code>get_ticker_earnings_trend(ticker, exchange='US', **kwargs)</code>","text":"<p>Retrieve earnings trend data for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing earnings trend data for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_financials","title":"<code>get_ticker_financials(ticker, exchange='US', **kwargs)</code>","text":"<p>Retrieve financial statements data for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Dictionary containing financial statements data for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_fundamentals","title":"<code>get_ticker_fundamentals(ticker, exchange='US', **kwargs)</code>","text":"<p>Get fundamental data for a specific ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol for the asset.</p> required <code>exchange</code> <code>str</code> <p>Exchange name. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Fundamental data for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_historical_mcap","title":"<code>get_ticker_historical_mcap(ticker, exchange, **kwargs)</code>","text":"<p>Retrieve historical market capitalization data for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing historical market capitalization data for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_insider_txn","title":"<code>get_ticker_insider_txn(ticker, exchange='US', **kwargs)</code>","text":"<p>Retrieve insider transaction data for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing insider transaction data for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_metadata","title":"<code>get_ticker_metadata(ticker, exchange='US', **kwargs)</code>","text":"<p>Retrieve metadata for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Metadata information for the ticker.</p> Notes <p>If the exchange is \"CC\", the metadata will be retrieved using the 'get_ticker_fundamentals' function.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_shares_stats","title":"<code>get_ticker_shares_stats(ticker, exchange='US', **kwargs)</code>","text":"<p>Retrieve shares statistics for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing shares statistics for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_splits","title":"<code>get_ticker_splits(ticker, exchange, **kwargs)</code>","text":"<p>Retrieve split data for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing split data for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_ticker_stat_snapshot","title":"<code>get_ticker_stat_snapshot(ticker, exchange='US', **kwargs)</code>","text":"<p>Retrieve a snapshot of various statistics for a ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol of the asset.</p> required <code>exchange</code> <code>str</code> <p>The exchange where the asset is traded. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>Snapshot of various statistics for the ticker.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_tickers_in_exchange","title":"<code>get_tickers_in_exchange(exchange, **kwargs)</code>","text":"<p>Get the list of tickers for a specific exchange.</p> <p>Parameters:</p> Name Type Description Default <code>exchange</code> <code>str</code> <p>Exchange name.</p> required <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the list of tickers for the exchange.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_trade_bars","title":"<code>get_trade_bars(ticker, start, end, granularity, granularity_multiplier, exchange='US', **kwargs)</code>","text":"<p>Retrieve trade bars data.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol for the asset.</p> required <code>start</code> <code>datetime</code> <p>Start datetime for the data retrieval.</p> required <code>end</code> <code>datetime</code> <p>End datetime for the data retrieval.</p> required <code>granularity</code> <code>Period</code> <p>Granularity of the data.</p> required <code>granularity_multiplier</code> <code>int</code> <p>Multiplier for the granularity.</p> required <code>exchange</code> <code>str</code> <p>Exchange name. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the trade bars data.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.get_trade_ticks","title":"<code>get_trade_ticks(ticker, start, end, exchange='US', **kwargs)</code>","text":"<p>Retrieve ticker ticks data.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol for the asset.</p> required <code>start</code> <code>datetime</code> <p>Start datetime for the data retrieval.</p> required <code>end</code> <code>datetime</code> <p>End datetime for the data retrieval.</p> required <code>exchange</code> <code>str</code> <p>Exchange name. Defaults to \"US\".</p> <code>'US'</code> <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the ticker ticks data.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.query_engine","title":"<code>query_engine(query, **kwargs)</code>","text":"<p>Perform a query using the Eodhd search engine.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <code>str</code> <p>The query string.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>DataFrame containing the results of the query.</p>"},{"location":"wrappers/eodhd/#quantpylib.wrappers.eodhd.Eodhd.stream_market_data","title":"<code>stream_market_data(ticker, stream_buffer, endpoint, **kwargs)</code>  <code>async</code>","text":"<p>Stream market data for a given ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>Ticker symbol for the asset.</p> required <code>stream_buffer</code> <code>defaultdict</code> <p>A dictionary that stores deque instances for streaming data.</p> required <code>endpoint</code> <p>Endpoint for streaming. Valid values are: <code>[\"us\", \"us-quote\", \"forex\", \"crypto\"]</code>.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code>"},{"location":"wrappers/oanda/","title":"quantpylib.wrappers.oanda","text":""},{"location":"wrappers/oanda/#quantpylib.wrappers.oanda.Oanda","title":"<code>Oanda</code>","text":"<p>A class for interacting with Oanda API for CFD data.    </p> Read <p>https://developer.oanda.com/rest-live-v20/introduction/</p>"},{"location":"wrappers/oanda/#quantpylib.wrappers.oanda.Oanda.__init__","title":"<code>__init__(account_id, secret, env='practice')</code>","text":"<p>Initialize the Oanda instance with the account ID, API token secret, and environment.</p> <p>Parameters:</p> Name Type Description Default <code>account_id</code> <code>str</code> <p>Oanda account ID.</p> required <code>secret</code> <code>str</code> <p>Oanda API token secret.</p> required <code>env</code> <code>str</code> <p>Environment type, either \"practice\" or \"live\".</p> <code>'practice'</code>"},{"location":"wrappers/oanda/#quantpylib.wrappers.oanda.Oanda.close_market_data_stream","title":"<code>close_market_data_stream(ticker, **kwargs)</code>  <code>async</code>","text":"<p>Close the streaming for market data of the specified ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The trading instrument ticker.</p> required <p>Returns:</p> Type Description <p>None</p>"},{"location":"wrappers/oanda/#quantpylib.wrappers.oanda.Oanda.get_ticker_metadata","title":"<code>get_ticker_metadata(ticker, **kwargs)</code>","text":"<p>Retrieve metadata for the specified ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The trading instrument ticker.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Metadata for the specified ticker.</p>"},{"location":"wrappers/oanda/#quantpylib.wrappers.oanda.Oanda.get_tickers_in_exchange","title":"<code>get_tickers_in_exchange(**kwargs)</code>","text":"<p>Retrieve the list of tickers available in the Oanda account.</p> <p>Returns:</p> Name Type Description <code>dict</code> <p>A dictionary of tickers available in the Oanda account.</p>"},{"location":"wrappers/oanda/#quantpylib.wrappers.oanda.Oanda.get_trade_bars","title":"<code>get_trade_bars(ticker, start, end, granularity, granularity_multiplier, **kwargs)</code>","text":"<p>Retrieve OHLCV trade bar data for the specified ticker and time range.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The trading instrument ticker.</p> required <code>start</code> <code>datetime</code> <p>The start date and time for data retrieval.</p> required <code>end</code> <code>datetime</code> <p>The end date and time for data retrieval.</p> required <code>granularity</code> <code>Period</code> <p>The period type for the OHLCV bars.</p> required <code>granularity_multiplier</code> <code>int</code> <p>The granularity multiplier.</p> required <p>Returns:</p> Type Description <p>pd.DataFrame: The OHLCV trade bar data for the specified ticker and time range.</p>"},{"location":"wrappers/oanda/#quantpylib.wrappers.oanda.Oanda.stream_market_data","title":"<code>stream_market_data(ticker, stream_buffer, **kwargs)</code>  <code>async</code>","text":"<p>Start streaming market data for the specified ticker.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The trading instrument ticker.</p> required <code>stream_buffer</code> <code>defaultdict</code> <p>A dictionary that stores deque instances for streaming data.</p> required <p>Returns:</p> Type Description <p>None</p>"},{"location":"wrappers/phemex/","title":"quantpylib.wrappers.phemex","text":""},{"location":"wrappers/yfinance/","title":"quantpylib.wrappers.yfinance","text":""},{"location":"wrappers/yfinance/#quantpylib.wrappers.yfinance.YFinance","title":"<code>YFinance</code>","text":""},{"location":"wrappers/yfinance/#quantpylib.wrappers.yfinance.YFinance.get_trade_bars","title":"<code>get_trade_bars(ticker, start, end, granularity, granularity_multiplier, **kwargs)</code>","text":"<p>Fetches trade bars data for the specified ticker and time period.</p> <p>Parameters:</p> Name Type Description Default <code>ticker</code> <code>str</code> <p>The ticker symbol.</p> required <code>start</code> <code>datetime</code> <p>The start date of the data to be fetched.</p> required <code>end</code> <code>datetime</code> <p>The end date of the data to be fetched.</p> required <code>granularity</code> <code>Period</code> <p>The granularity of the data.</p> required <code>granularity_multiplier</code> <code>int</code> <p>The multiplier for the granularity.</p> required <code>**kwargs</code> <p>Additional keyword arguments.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>The DataFrame containing the trade bars data.</p>"}]}